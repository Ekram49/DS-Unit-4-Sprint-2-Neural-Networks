{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ekram LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekram49/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Ekram_LS_DS_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer: The visible layer that interacts directly with the database to get inputs.\n",
        "### Hidden Layer: Layers after the input layer that cannot be accessed directly.\n",
        "### Output Layer: The layer that ouputs the results in a form suitable for the problem\n",
        "### Neuron: A single node.\n",
        "### Weight: The value that an input is multiplied by. A scaling factor between nodes\n",
        "### Activation Function: The function that takes model results and converts them into a for that is suitable for the problem.\n",
        "### Node Map: A topological map of a neural network detailing the nodes and their connections.\n",
        "### Perceptron: The simplest form of neural network that simply takes an input and returns a weighted ouput\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Your Answer Here\n",
        "\n",
        "The neural net recieves inputs through the input node. The inputs are then sent into corresponding hidden nodes (one for each features) where weights are applied to them. Biases are added to the values and the results are passed into additional hidden layers if there are any. After the last hidden layer, the results are passed into an activation function which formats the results into a response that suits the problem (e.g. converting values to a range from 0,1 for probabilities). The results are then ouputted by the output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCvwWYVjtVih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "98da1e50-7ed1-47b2-a3f7-59ea16231c1a"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   1   0  1\n",
              "2   0   1  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7clcUZc7tQFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJi9yaHNswXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = np.array([\n",
        "                   [0,0,1],\n",
        "                   [1,0,1],\n",
        "                   [0,1,1],\n",
        "                   [1,1,0]\n",
        "])\n",
        "\n",
        "correct_outputs = [[1], [1], [1], [0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CdPqfkuteaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivate(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl_mc3Xnt1-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b9b56ccf-c297-40d5-d7a4-a793661da855"
      },
      "source": [
        "weights = 2 * np.random.random((3,1)) - 1\n",
        "weights"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.46775406],\n",
              "       [ 0.0401636 ],\n",
              "       [-0.47231814]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSDL4e0Nt6Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znP-VxLVt8Zc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "fa860868-f129-47ca-cf7d-e243f72028b9"
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38406772],\n",
              "       [0.28088576],\n",
              "       [0.39361196],\n",
              "       [0.39470185]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqYwE4m9t-LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b75a6ebe-d186-4a64-960e-26e94ec6b873"
      },
      "source": [
        "error = correct_outputs - activated_output\n",
        "error"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.61593228],\n",
              "       [ 0.71911424],\n",
              "       [ 0.60638804],\n",
              "       [-0.39470185]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdJOSvl_uH5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c9375c61-9b10-498c-95da-56403217d03e"
      },
      "source": [
        "adjustments = error * sigmoid_derivate(weighted_sum)\n",
        "adjustments"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.14570476],\n",
              "       [ 0.14525313],\n",
              "       [ 0.14473366],\n",
              "       [-0.09429913]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj4CMwG0uPAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "37fca4dd-0a31-4ed5-9e65-fb4d09b54578"
      },
      "source": [
        "weights += np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.41680006],\n",
              "       [ 0.09059813],\n",
              "       [-0.03662659]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD8oUCoVuTtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "6ac80aa0-6b40-43e0-834c-b9faff783609"
      },
      "source": [
        "# Update our weights 10,000 times - (fingers crossed that this process reduces error)\n",
        "for iteration in range(10000):\n",
        "    \n",
        "    # Weighted sum of inputs / weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "    \n",
        "    # Activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "    \n",
        "    # Cac error\n",
        "    error = correct_outputs - activated_output\n",
        "    \n",
        "    # Can add in learning rate for better performance.\n",
        "    adjustments = error * sigmoid_derivate(weighted_sum)\n",
        "    \n",
        "    # Update the Weights\n",
        "    weights += np.dot(inputs.T, adjustments)\n",
        "    \n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-2.41126533]\n",
            " [-2.40925153]\n",
            " [ 7.49031259]]\n",
            "Output after training\n",
            "[[0.9994418 ]\n",
            " [0.99381237]\n",
            " [0.99382474]\n",
            " [0.00799854]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COr0aeR4tVip",
        "colab_type": "code",
        "outputId": "f268ee40-dbf8-4552-d976-9870402788f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9z6iNdntVis",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xycPzqDvtVis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "81a73801-5e41-455e-b1aa-f2110c731c65"
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "# train test split\n",
        "\n",
        "X = diabetes.drop('Outcome', axis=1)\n",
        "y = diabetes['Outcome']\n",
        "\n",
        "# fitting the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=feats)\n",
        "X_scaled.head()\n",
        "\"\"\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.preprocessing import MinMaxScaler, Normalizer\\n\\nfeats = list(diabetes)[:-1]\\n# train test split\\n\\nX = diabetes.drop('Outcome', axis=1)\\ny = diabetes['Outcome']\\n\\n# fitting the data\\nscaler = MinMaxScaler()\\nX_scaled = pd.DataFrame(scaler.fit_transform(X), columns=feats)\\nX_scaled.head()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P8cRhwn6VJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6162e219-1bbf-404e-dfbd-3a566a86b55e"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "# Set the features as an array without the last column\n",
        "features = list(diabetes)[:-1]\n",
        "\n",
        "# Set the minmaxscalar\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit transform on the data with the set features\n",
        "X = scaler.fit_transform(diabetes[features])\n",
        "\n",
        "# Show the data\n",
        "X"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SDMJcTE4Hgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "fcece273-c2fc-48cf-c714-7858db712d2c"
      },
      "source": [
        "# Set the target with the last column (correct_outcome/y)\n",
        "y = diabetes.iloc[:, 8].values\n",
        "\n",
        "# Show the array\n",
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "\n",
        "# perceptron class.\n",
        "class Perceptron(object):\n",
        "    \n",
        "    def __init__(self, niter = 10000):\n",
        "        self.niter = niter\n",
        "    # sigmoid activation function.\n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    # sigmoid derivative function to update weights.\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        sx = sigmoid(x)\n",
        "        return sx * (1-sx)\n",
        "    # predict function.\n",
        "    def predict(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "\n",
        "        # randomly initialize weights\n",
        "        self.weight = np.zeros(X.shape[1])\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            # sum up the weights.\n",
        "            weighted_sum = np.dot(X, self.weight)  \n",
        "            # use the sigmoid function on the weighted sum.\n",
        "            activated_output = sigmoid(weighted_sum)   \n",
        "            # find the calculation error.\n",
        "            error = y - activated_output   \n",
        "            # use the derivative function on the avivated outputs.\n",
        "            adjustments = error * sigmoid_derivative(activated_output)   \n",
        "            # update the weights with adjustments.\n",
        "            self.weight += np.dot(X.T, adjustments)\n",
        "\n",
        "        return activated_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54FDMDG05cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, niter = 10):\n",
        "        self.niter = niter\n",
        "    \n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        sx = sigmoid(x)\n",
        "        return sx * (1-sx)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "    \"\"\"Fit training data\n",
        "    X : Training vectors, X.shape : [#samples, #features]\n",
        "    y : Target values, y.shape : [#samples]\n",
        "    \"\"\"\n",
        "\n",
        "        # Randomly Initialize Weights\n",
        "        self.weight = np.zeros(1 + X.shape[1])\n",
        "        self.inputs = X.values.tolist()\n",
        "        self.outputs = y.values.tolist()\n",
        "\n",
        "            # Weighted sum of inputs / weights\n",
        "\n",
        "            # Activate!\n",
        "            #activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "            # Cac error\n",
        "            #error = correct_outputs - activated_output\n",
        "\n",
        "            # Update the Weights\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "    \"\"\"Return class label after unit step\"\"\"\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}