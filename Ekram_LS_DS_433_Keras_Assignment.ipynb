{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ekram LS_DS_433_Keras_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekram49/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Ekram_LS_DS_433_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH3Oop8M9Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import statements\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rts1z7JNoN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "735eef20-76ee-468d-a77e-0cb85df60882"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
              "        3.96900e+02, 1.87200e+01],\n",
              "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
              "        3.95380e+02, 3.11000e+00],\n",
              "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
              "        3.75520e+02, 3.26000e+00],\n",
              "       ...,\n",
              "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
              "        3.62250e+02, 7.83000e+00],\n",
              "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "        2.61950e+02, 1.57900e+01],\n",
              "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
              "        3.76700e+02, 4.38000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ecoBmyNuE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "b4de23b0-7388-46ed-fa69-d675a2a9d6ed"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
              "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
              "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
              "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
              "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
              "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
              "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
              "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
              "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
              "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
              "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
              "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
              "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
              "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
              "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
              "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
              "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
              "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
              "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
              "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
              "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
              "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
              "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
              "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
              "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
              "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
              "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
              "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
              "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
              "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
              "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
              "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
              "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
              "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
              "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
              "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD52wRx8NyMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalization\n",
        "X_train = Normalizer().fit_transform(X_train)\n",
        "X_test = Normalizer().fit_transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTl0PRy8Sq9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "687ea7bf-c56d-4a51-a5bd-1743d637219d"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(102, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woFs48h9PvMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9879c13-16d2-481f-ade7-12813d97b2f4"
      },
      "source": [
        "# Instantiate a model object and use model.add() to add layers to your model\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "stop = EarlyStopping(monitor='mean_squared_error', min_delta=0.01, patience=3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_shape=(13,), activation='relu')) #elu 10\n",
        "model.add(Dense(100, activation='relu')) \n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "# Compile your model\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['MeanSquaredError'])\n",
        "\n",
        "# Fit your model\n",
        "result = model.fit(x=X_train, \n",
        "        y=y_train, \n",
        "        epochs=100, \n",
        "        validation_data=(X_test, y_test), \n",
        "        callbacks=[tensorboard_callback])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 21.9592 - mean_squared_error: 566.4377 - val_loss: 22.1787 - val_mean_squared_error: 574.6246\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 21.0395 - mean_squared_error: 526.7584 - val_loss: 21.0659 - val_mean_squared_error: 526.1984\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 19.6234 - mean_squared_error: 468.2711 - val_loss: 19.1687 - val_mean_squared_error: 449.3349\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 17.1850 - mean_squared_error: 378.9712 - val_loss: 15.9525 - val_mean_squared_error: 334.6120\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 13.2153 - mean_squared_error: 255.4653 - val_loss: 11.4041 - val_mean_squared_error: 195.3722\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 8.3535 - mean_squared_error: 135.2259 - val_loss: 7.0142 - val_mean_squared_error: 94.4571\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6.2797 - mean_squared_error: 82.1511 - val_loss: 6.2906 - val_mean_squared_error: 77.1373\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.1801 - mean_squared_error: 77.3865 - val_loss: 6.2393 - val_mean_squared_error: 79.4578\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.9864 - mean_squared_error: 78.4913 - val_loss: 6.3200 - val_mean_squared_error: 80.8413\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.9085 - mean_squared_error: 77.0664 - val_loss: 6.1438 - val_mean_squared_error: 76.8830\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.8001 - mean_squared_error: 74.3784 - val_loss: 6.1125 - val_mean_squared_error: 75.9941\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.7095 - mean_squared_error: 74.2352 - val_loss: 6.1164 - val_mean_squared_error: 75.9034\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.6251 - mean_squared_error: 72.8555 - val_loss: 5.9752 - val_mean_squared_error: 72.6255\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.5511 - mean_squared_error: 70.3302 - val_loss: 5.9293 - val_mean_squared_error: 71.4623\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.4819 - mean_squared_error: 70.7420 - val_loss: 5.9768 - val_mean_squared_error: 72.3791\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.4317 - mean_squared_error: 69.1979 - val_loss: 5.8658 - val_mean_squared_error: 69.5182\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.3861 - mean_squared_error: 69.2032 - val_loss: 5.8922 - val_mean_squared_error: 69.9483\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.3324 - mean_squared_error: 67.7096 - val_loss: 5.8387 - val_mean_squared_error: 68.1532\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.2799 - mean_squared_error: 67.2229 - val_loss: 5.8852 - val_mean_squared_error: 69.4192\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2628 - mean_squared_error: 66.6081 - val_loss: 5.8301 - val_mean_squared_error: 67.5926\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2109 - mean_squared_error: 66.5600 - val_loss: 5.8760 - val_mean_squared_error: 69.0057\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.1882 - mean_squared_error: 66.9664 - val_loss: 5.8063 - val_mean_squared_error: 66.7430\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.1700 - mean_squared_error: 66.1944 - val_loss: 5.7989 - val_mean_squared_error: 66.5199\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.1285 - mean_squared_error: 64.8834 - val_loss: 5.7580 - val_mean_squared_error: 65.3067\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.1097 - mean_squared_error: 63.5090 - val_loss: 5.7564 - val_mean_squared_error: 65.2822\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0998 - mean_squared_error: 65.1266 - val_loss: 5.7905 - val_mean_squared_error: 66.4372\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.0877 - mean_squared_error: 62.8739 - val_loss: 5.7312 - val_mean_squared_error: 64.6427\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0802 - mean_squared_error: 65.5432 - val_loss: 5.7899 - val_mean_squared_error: 66.5176\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0583 - mean_squared_error: 62.0201 - val_loss: 5.6631 - val_mean_squared_error: 62.7242\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0302 - mean_squared_error: 64.2836 - val_loss: 5.7953 - val_mean_squared_error: 66.8092\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9971 - mean_squared_error: 63.4313 - val_loss: 5.6797 - val_mean_squared_error: 63.4339\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9783 - mean_squared_error: 62.2001 - val_loss: 5.6887 - val_mean_squared_error: 63.7783\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9617 - mean_squared_error: 62.8313 - val_loss: 5.7538 - val_mean_squared_error: 65.7751\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9505 - mean_squared_error: 63.6649 - val_loss: 5.6833 - val_mean_squared_error: 63.5928\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9625 - mean_squared_error: 60.9997 - val_loss: 5.6772 - val_mean_squared_error: 63.4216\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9246 - mean_squared_error: 62.6391 - val_loss: 5.6827 - val_mean_squared_error: 63.6131\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9149 - mean_squared_error: 61.3976 - val_loss: 5.6890 - val_mean_squared_error: 63.8379\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9036 - mean_squared_error: 62.1127 - val_loss: 5.7096 - val_mean_squared_error: 64.5453\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9006 - mean_squared_error: 61.2013 - val_loss: 5.6409 - val_mean_squared_error: 62.4378\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8870 - mean_squared_error: 61.2606 - val_loss: 5.6951 - val_mean_squared_error: 64.1825\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8716 - mean_squared_error: 62.5346 - val_loss: 5.6135 - val_mean_squared_error: 61.7727\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8872 - mean_squared_error: 59.4628 - val_loss: 5.6728 - val_mean_squared_error: 63.5701\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8568 - mean_squared_error: 61.4905 - val_loss: 5.6443 - val_mean_squared_error: 62.7395\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8449 - mean_squared_error: 60.6703 - val_loss: 5.6682 - val_mean_squared_error: 63.5045\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8359 - mean_squared_error: 60.4481 - val_loss: 5.6086 - val_mean_squared_error: 61.7993\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8115 - mean_squared_error: 60.6299 - val_loss: 5.6486 - val_mean_squared_error: 63.0725\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8131 - mean_squared_error: 60.2761 - val_loss: 5.5979 - val_mean_squared_error: 61.6200\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8026 - mean_squared_error: 60.4781 - val_loss: 5.6281 - val_mean_squared_error: 62.5672\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7855 - mean_squared_error: 59.9142 - val_loss: 5.5690 - val_mean_squared_error: 60.9506\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7925 - mean_squared_error: 59.6268 - val_loss: 5.5533 - val_mean_squared_error: 60.5903\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7751 - mean_squared_error: 58.8953 - val_loss: 5.6055 - val_mean_squared_error: 62.0612\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7945 - mean_squared_error: 60.6905 - val_loss: 5.5488 - val_mean_squared_error: 60.5967\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7685 - mean_squared_error: 59.1055 - val_loss: 5.5677 - val_mean_squared_error: 61.1736\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7511 - mean_squared_error: 58.6275 - val_loss: 5.5611 - val_mean_squared_error: 61.0689\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7569 - mean_squared_error: 58.6282 - val_loss: 5.6384 - val_mean_squared_error: 63.2615\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7533 - mean_squared_error: 59.8048 - val_loss: 5.5317 - val_mean_squared_error: 60.4586\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7381 - mean_squared_error: 57.9354 - val_loss: 5.5476 - val_mean_squared_error: 60.9524\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7382 - mean_squared_error: 59.9473 - val_loss: 5.5969 - val_mean_squared_error: 62.3119\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7596 - mean_squared_error: 57.4685 - val_loss: 5.5122 - val_mean_squared_error: 60.1275\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7742 - mean_squared_error: 60.6955 - val_loss: 5.5145 - val_mean_squared_error: 60.2875\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7651 - mean_squared_error: 56.2265 - val_loss: 5.5224 - val_mean_squared_error: 60.5134\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7040 - mean_squared_error: 59.0947 - val_loss: 5.5481 - val_mean_squared_error: 61.1642\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.7065 - mean_squared_error: 57.0348 - val_loss: 5.4804 - val_mean_squared_error: 59.5007\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7280 - mean_squared_error: 59.3036 - val_loss: 5.5136 - val_mean_squared_error: 60.4183\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6831 - mean_squared_error: 57.1192 - val_loss: 5.4979 - val_mean_squared_error: 60.0884\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6863 - mean_squared_error: 58.1673 - val_loss: 5.5288 - val_mean_squared_error: 60.8749\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6691 - mean_squared_error: 57.5729 - val_loss: 5.4498 - val_mean_squared_error: 58.9158\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6632 - mean_squared_error: 57.5053 - val_loss: 5.5116 - val_mean_squared_error: 60.5252\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6633 - mean_squared_error: 57.6629 - val_loss: 5.4901 - val_mean_squared_error: 60.0235\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6566 - mean_squared_error: 57.6196 - val_loss: 5.4396 - val_mean_squared_error: 58.8182\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6526 - mean_squared_error: 56.2990 - val_loss: 5.4809 - val_mean_squared_error: 59.8996\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6405 - mean_squared_error: 57.4338 - val_loss: 5.4688 - val_mean_squared_error: 59.6288\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6376 - mean_squared_error: 56.5291 - val_loss: 5.4588 - val_mean_squared_error: 59.4187\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6543 - mean_squared_error: 56.2141 - val_loss: 5.5094 - val_mean_squared_error: 60.7085\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6435 - mean_squared_error: 58.2252 - val_loss: 5.4096 - val_mean_squared_error: 58.2988\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6225 - mean_squared_error: 55.1494 - val_loss: 5.4530 - val_mean_squared_error: 59.3812\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6721 - mean_squared_error: 59.1129 - val_loss: 5.4250 - val_mean_squared_error: 58.7489\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6292 - mean_squared_error: 55.0586 - val_loss: 5.4406 - val_mean_squared_error: 59.1818\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6047 - mean_squared_error: 57.3213 - val_loss: 5.4199 - val_mean_squared_error: 58.7392\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5921 - mean_squared_error: 56.0028 - val_loss: 5.4064 - val_mean_squared_error: 58.4854\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5801 - mean_squared_error: 55.6304 - val_loss: 5.3652 - val_mean_squared_error: 57.5030\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6256 - mean_squared_error: 57.5133 - val_loss: 5.4021 - val_mean_squared_error: 58.5029\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6022 - mean_squared_error: 54.4644 - val_loss: 5.3971 - val_mean_squared_error: 58.4249\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5771 - mean_squared_error: 56.9490 - val_loss: 5.4098 - val_mean_squared_error: 58.7685\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5613 - mean_squared_error: 55.0948 - val_loss: 5.3712 - val_mean_squared_error: 57.8587\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5542 - mean_squared_error: 55.5997 - val_loss: 5.3778 - val_mean_squared_error: 58.0612\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5467 - mean_squared_error: 54.8994 - val_loss: 5.3249 - val_mean_squared_error: 56.7749\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5677 - mean_squared_error: 55.6607 - val_loss: 5.3139 - val_mean_squared_error: 56.5389\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5504 - mean_squared_error: 53.3959 - val_loss: 5.3354 - val_mean_squared_error: 57.1870\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5432 - mean_squared_error: 55.4995 - val_loss: 5.3236 - val_mean_squared_error: 56.9796\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5204 - mean_squared_error: 54.6557 - val_loss: 5.2840 - val_mean_squared_error: 55.9391\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5126 - mean_squared_error: 54.6913 - val_loss: 5.3398 - val_mean_squared_error: 57.4462\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5027 - mean_squared_error: 54.0361 - val_loss: 5.3175 - val_mean_squared_error: 56.9924\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5361 - mean_squared_error: 54.5190 - val_loss: 5.2595 - val_mean_squared_error: 55.5123\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5450 - mean_squared_error: 56.4061 - val_loss: 5.3648 - val_mean_squared_error: 58.1076\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4824 - mean_squared_error: 53.7876 - val_loss: 5.2601 - val_mean_squared_error: 55.7238\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4860 - mean_squared_error: 53.3977 - val_loss: 5.3624 - val_mean_squared_error: 58.0994\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4943 - mean_squared_error: 54.0999 - val_loss: 5.2315 - val_mean_squared_error: 55.0735\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4551 - mean_squared_error: 53.0202 - val_loss: 5.3191 - val_mean_squared_error: 57.2617\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4935 - mean_squared_error: 55.1921 - val_loss: 5.1743 - val_mean_squared_error: 53.5702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT2h7Lp3eK_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d89a23d0-a05f-42fd-d5ad-30d22cec4eab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "\n",
        "plt.title('Model Loss ')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show();"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxcd33v/9dnFs1Io8XaLK+JjZ2drJiQEJYsLEngslx6AymU5cIN8KA03NubEm6h/Oi9vaX3FspWaFlc9tA0kEIvARIgEFISwNmIExvsrJZXWbZ2jTTL5/fH98ieKCNbljQaZ+b9fDzmIc1ZZj7Hk8xb3+WcY+6OiIjIdLFqFyAiIscnBYSIiJSlgBARkbIUECIiUpYCQkREylJAiIhIWQoIkWNkZmvMzM0sMYtt32pmdy5GXSILTQEhNc3MHjezSTPrmrb8vuhLfk11Kju2oBGpBgWE1IPHgKunnpjZmUBT9coReWZQQEg9+Brw5pLnbwG+WrqBmbWZ2VfNrM/MnjCzD5pZLFoXN7O/NbP9ZvYo8Ioy+37JzHab2U4z+19mFp9PwWa2wsy+Z2YHzGy7mf2XknXnm9kmMxsys71m9vFoedrMvm5m/WY2YGa/MbOe+dQh9U0BIfXgbqDVzE6LvrjfAHx92jafBtqAZwEvJgTK26J1/wV4JXAusAH4g2n7fhnIA+ujbV4GvGOeNX8L6AVWRO/3v83s0mjdJ4FPunsrsA64MVr+lugYVgOdwLuA8XnWIXVMASH1YqoV8VJgC7BzakVJaHzA3Yfd/XHgY8AfRZtcBXzC3Xe4+wHgr0v27QGuBN7n7qPuvg/4u+j15sTMVgMXAe9396y73w98kcOtoByw3sy63H3E3e8uWd4JrHf3grvf4+5Dc61DRAEh9eJrwB8Cb2Va9xLQBSSBJ0qWPQGsjH5fAeyYtm7KidG+u6NunQHgH4Gl86h1BXDA3YdnqOftwMnA1qgb6ZXR8q8BPwK+ZWa7zOz/mFlyHnVInVNASF1w9ycIg9VXAt+Ztno/4a/vE0uWncDhVsZuQrdN6bopO4AJoMvdl0SPVnc/Yx7l7gI6zKylXD3uvs3dryaE0N8AN5lZxt1z7v4Rdz8deD6hW+zNiMyRAkLqyduBS919tHShuxcI/fh/ZWYtZnYi8N84PE5xI/AnZrbKzNqB60v23Q3cCnzMzFrNLGZm68zsxcdQVyoaYE6bWZoQBL8E/jpadlZU+9cBzOxNZtbt7kVgIHqNopldYmZnRl1mQ4TQKx5DHSJPoYCQuuHuj7j7phlWvxcYBR4F7gS+CWyM1n2B0HXzAHAvT2+BvBloAB4GDgI3AcuPobQRwmDy1ONSwrTcNYTWxM3Ah939x9H2lwMPmdkIYcD6De4+DiyL3nuIMM7yc0K3k8icmG4YJCIi5agFISIiZSkgRESkLAWEiIiUpYAQEZGyauoqkl1dXb5mzZpqlyEi8oxxzz337Hf37nLraiog1qxZw6ZNM81iFBGR6czsiZnWqYtJRETKUkCIiEhZFQsIM1ttZreb2cNm9pCZXRst/79mttXMfmtmN5vZkhn2f9zMHjSz+81M/UYiIouskmMQeeBP3f3e6KJj95jZbcBthMsq583sb4APAO+f4TUucff9FaxRROpcLpejt7eXbDZb7VIqKp1Os2rVKpLJ2V/gt2IBEV3EbHf0+7CZbQFWuvutJZvdzdNvviIismh6e3tpaWlhzZo1mFm1y6kId6e/v5/e3l7Wrl076/0WZQwiujH8ucCvpq36z8APZtjNgVvN7B4zu+YIr31NdPvFTX19fQtRrojUkWw2S2dnZ82GA4CZ0dnZecytpIoHhJk1A98m3HFrqGT5nxO6ob4xw64vcPfzgCuA95jZi8pt5O6fd/cN7r6hu7vsVF4RkSOq5XCYMpdjrGhARHez+jbwDXf/TsnytxJuZvJGn+Fysu4+dXOUfYTLHZ9fkSLzE3DnJ+CRn1bk5UVEnqkqOYvJgC8BW9z94yXLLwf+DHiVu4/NsG9m6m5aZpYh3AR+c0UKjTfALz8Nv73x6NuKiCywgYEBPvvZzx7zfldeeSUDAwNH33AeKtmCuIhw0/dLo6mq95vZlcBngBbgtmjZPwCY2QozuyXatwe408weAH4NfN/df1iRKs3Ir76Q4mN3VuTlRUSOZKaAyOfzR9zvlltuYcmSsmcJLJhKzmK6EyjX6XVLmWW4+y7C/YJx90eBsytVW6nxyQIf39LFn8d2wMEnoP3Eo+8kIrJArr/+eh555BHOOecckskk6XSa9vZ2tm7dyu9//3te85rXsGPHDrLZLNdeey3XXBPm7ExdWmhkZIQrrriCF7zgBfzyl79k5cqVfPe736WxsXHetdXUtZjmorEhzsGl58P+f4In/l0BIVLHPvJvD/HwrqGjb3gMTl/Ryof/wxkzrv/oRz/K5s2buf/++/nZz37GK17xCjZv3nxoOurGjRvp6OhgfHyc5z73ubzuda+js7PzKa+xbds2brjhBr7whS9w1VVX8e1vf5s3velN865dl9oATj7zuRz0ZkZ///NqlyIide78889/yrkKn/rUpzj77LO54IIL2LFjB9u2bXvaPmvXruWcc84B4DnPeQ6PP/74gtRS9y0IgMtOX86vfnwaFz32i2qXIiJVdKS/9BdLJpM59PvPfvYzfvzjH3PXXXfR1NTExRdfXPZchlQqdej3eDzO+Pj4gtSiFgSwrruZ7Y1n0zK+EwZ7q12OiNSRlpYWhoeHy64bHBykvb2dpqYmtm7dyt13372otSkgIqn1LwQgu/2OKlciIvWks7OTiy66iGc/+9lcd911T1l3+eWXk8/nOe2007j++uu54IILFrU2m+E8tWekDRs2+FxvGPTL7fs4/WvnMLz2Cla/9UsLXJmIHK+2bNnCaaedVu0yFkW5YzWze9x9Q7nt1YKIPHdtF/fZaaR33VXtUkREjgsKiEgyHuNg9/l0T+6kOLCz2uWIiFSdAqJE++mXAvDkfbdVuRIRkepTQJQ497kvYNgbGdiq8yFERBQQJZY0N9KbPJHkwe3VLkVEpOoUENOMt6yha3IHtTS7S0RkLhQQ08S61tPDQXbu6692KSJSB+Z6uW+AT3ziE4yNlb1rwoJQQEyzZFWYI/z47x+sciUiUg+O54DQtZimWf6sM+B2OLBjC3BJtcsRkRpXernvl770pSxdupQbb7yRiYkJXvva1/KRj3yE0dFRrrrqKnp7eykUCnzoQx9i79697Nq1i0suuYSuri5uv/32Ba9NATFNaul6ACb2Pf2KiSJS435wPexZ4N6DZWfCFR+dcXXp5b5vvfVWbrrpJn7961/j7rzqVa/ijjvuoK+vjxUrVvD9738fCNdoamtr4+Mf/zi33347XV1dC1tzRF1M06VaGEp0kBp8TAPVIrKobr31Vm699VbOPfdczjvvPLZu3cq2bds488wzue2223j/+9/PL37xC9ra2halHrUgyhhrXsvyAzvZNzxBT2u62uWIyGI5wl/6i8Hd+cAHPsA73/nOp6279957ueWWW/jgBz/IZZddxl/8xV9UvJ6KtSDMbLWZ3W5mD5vZQ2Z2bbS8w8xuM7Nt0c/2GfZ/S7TNNjN7S6XqLCfevY41tofNOwcX821FpA6VXu775S9/ORs3bmRkZASAnTt3sm/fPnbt2kVTUxNvetObuO6667j33nuftm8lVLIFkQf+1N3vNbMW4B4zuw14K/ATd/+omV0PXA+8v3RHM+sAPgxsADza93vufrCC9R7SuvJUUttuZNuTu7jstJ7FeEsRqVOll/u+4oor+MM//EMuvPBCAJqbm/n617/O9u3bue6664jFYiSTST73uc8BcM0113D55ZezYsWKZ9YgtbvvBnZHvw+b2RZgJfBq4OJos68AP2NaQAAvB25z9wMAUbBcDtxQqXpLpZaeBMD+J7cA5y7GW4pIHfvmN7/5lOfXXnvtU56vW7eOl7/85U/b773vfS/vfe97K1bXogxSm9kawjftr4CeKDwA9gDl/kRfCewoed4bLVscnesAyGkmk4jUsYoHhJk1A98G3ufuQ6XrPEwTmtdUITO7xsw2mdmmvr6++bzUYR3PAqBt7EkOjE4uzGuKiDzDVDQgzCxJCIdvuPt3osV7zWx5tH45sK/MrjuB1SXPV0XLnsbdP+/uG9x9Q3d398IUnmxkomk5a2J7eGiXBqpFal09TGmfyzFWchaTAV8Ctrj7x0tWfQ+YmpX0FuC7ZXb/EfAyM2uPZjm9LFq2aGJd61lre3ho19DRNxaRZ6x0Ok1/f39Nh4S709/fTzp9bNP2KzmL6SLgj4AHzez+aNn/AD4K3GhmbweeAK4CMLMNwLvc/R3ufsDM/ifwm2i/v5wasF4sye71POvJ+9iogBCpaatWraK3t5cF66I+TqXTaVatWnVM+1RyFtOdgM2w+rIy228C3lHyfCOwsTLVzULnOtoYYWD/nqqVICKVl0wmWbt2bbXLOC7pUhsz6QzXZGoYfKzKhYiIVIcCYiYdYapr2/iT5ArFKhcjIrL4FBAzaV9DkRgn2h72DmWrXY2IyKJTQMwk0cBEZgVrbQ+7BxUQIlJ/FBBH4K0r6bGD7BoYr3YpIiKLTgFxBMnWHjoYVgtCROqSAuIIkq1L6bIhdqsFISJ1SAFxJJlu2m2YPQOj1a5ERGTRKSCOJBPu8zo2sLfKhYiILD4FxJE0hYDIDSkgRKT+KCCOJBOuDhsf72ciX6hyMSIii0sBcSRRQHQyxB7NZBKROqOAOJJoDKLLhtg1oIAQkfqigDiS9BI8lqDTBtk9qKmuIlJfFBBHEotBUxedDOlkORGpOwqIo7BMN8sTw7rchojUHQXE0WS66ImPqAUhInVHAXE0mW46bVAtCBGpOwqIo8l001ocVAtCROpOxe5JbWYbgVcC+9z92dGyfwZOiTZZAgy4+zll9n0cGAYKQN7dN1SqzqPKdJEqjjOZHWZsMk9TQ8X+yUREjiuV/Lb7MvAZ4KtTC9z99VO/m9nHgMEj7H+Ju++vWHWzNXWynA2zayDL+qXNVS5IRGRxVKyLyd3vAA6UW2dmBlwF3FCp918wh86m1rkQIlJfqjUG8UJgr7tvm2G9A7ea2T1mds2RXsjMrjGzTWa2qa+vb8ELPdyC0LkQIlJfqhUQV3Pk1sML3P084ArgPWb2opk2dPfPu/sGd9/Q3d290HUeutxGpw2xW5fbEJE6sugBYWYJ4D8C/zzTNu6+M/q5D7gZOH9xqisjCogTUmPqYhKRulKNFsRLgK3u3ltupZllzKxl6nfgZcDmRazvqRoykMywumGUXepiEpE6UrGAMLMbgLuAU8ys18zeHq16A9O6l8xshZndEj3tAe40sweAXwPfd/cfVqrOWcl00RMfpn9koqpliIgspopNc3X3q2dY/tYyy3YBV0a/PwqcXam65iTTTfvAIANjuWpXIiKyaHQm9WxkumkrDjA0roAQkfqhgJiNTBcthQGGJ/LkCsVqVyMisigUELOR6aYpdxBwtSJEpG4oIGYj003M87QyyoACQkTqhAJiNqKzqbtsSAPVIlI3FBCzkekEoJMhdTGJSN1QQMxGyfWYBsYnq1yMiMjiUEDMxqEuJp0LISL1QwExG02Hu5gUECJSLxQQsxFPQmM7y5PDDGoMQkTqhAJitjLd9MRHFBAiUjcUELOV6abbhhgY0yC1iNQHBcRspZfQamM6UU5E6oYCYrbSbTT7KIMapBaROqGAmK10K43FUY1BiEjdUEDMVrqNdHGUwfEJ3L3a1YiIVJwCYrZSrRhOY3GckYl8tasREak4BcRspdsAwhVdNQ4hInVAATFb6VYAWmxc4xAiUhcqFhBmttHM9pnZ5pJl/5+Z7TSz+6PHlTPse7mZ/c7MtpvZ9ZWq8ZiUtCAUECJSDyrZgvgycHmZ5X/n7udEj1umrzSzOPD3wBXA6cDVZnZ6BeucndRUC2JMXUwiUhcqFhDufgdwYA67ng9sd/dH3X0S+Bbw6gUtbi4OtSDGdMlvEakL1RiD+GMz+23UBdVeZv1KYEfJ895oWVlmdo2ZbTKzTX19fQtd62FRQKgFISL1YrED4nPAOuAcYDfwsfm+oLt/3t03uPuG7u7u+b7czKIupo64BqlFpD4sakC4+153L7h7EfgCoTtpup3A6pLnq6Jl1ZVogEQjXYkJXW5DROrCogaEmS0vefpaYHOZzX4DnGRma82sAXgD8L3FqO+o0m10xsc1BiEidSFRqRc2sxuAi4EuM+sFPgxcbGbnAA48Drwz2nYF8EV3v9Ld82b2x8CPgDiw0d0fqlSdxyTdypL8uMYgRKQuVCwg3P3qMou/NMO2u4ArS57fAjxtCmzVpdtoGx3TGISI1AWdSX0sUq00o1lMIlIfFBDHIt1GxnUmtYjUBwXEsUi30lgYZTxXIJsrVLsaEZGKUkAci3QbqcIwAENqRYhIjVNAHItUK/HiJCkmdW9qEal5swoIM8uYWSz6/WQze5WZJStb2nFo6nIb6GxqEal9s21B3AGkzWwlcCvwR4SrtdYXXY9JROrIbAPC3H0M+I/AZ939PwFnVK6s49RT7iqns6lFpLbNOiDM7ELgjcD3o2XxypR0HIsu2NdqOllORGrfbAPifcAHgJvd/SEzexZwe+XKOk5FLYg20+U2RKT2zepSG+7+c+DnANFg9X53/5NKFnZciu5LvbQhqxaEiNS82c5i+qaZtZpZhnAF1ofN7LrKlnYciloQ3ckJTXMVkZo32y6m0919CHgN8ANgLWEmU31paAaL0ZkY1yC1iNS82QZEMjrv4TXA99w9R7hkd30xg1QrHXF1MYlI7ZttQPwj4f4NGeAOMzsRGKpUUce1dBttmsUkInVgVgHh7p9y95XRDX3c3Z8ALqlwbcendLjk90g2X+1KREQqaraD1G1m9nEz2xQ9PkZoTdSf9BKafZRhBYSI1LjZdjFtBIaBq6LHEPBPlSrquJZqpbE4ymShyERel/wWkdo121uOrnP315U8/4iZ3V+Jgo576TbShREAhrN5Us31d0K5iNSH2bYgxs3sBVNPzOwiYPxIO5jZRjPbZ2abS5b9XzPbama/NbObzWzJDPs+bmYPmtn9ZrZpljUujnQrDfkQEBqHEJFaNtuAeBfw99EX9+PAZ4B3HmWfLwOXT1t2G/Bsdz8L+D3h8h0zucTdz3H3DbOscXGk20jmRzCKGocQkZo221lMD7j72cBZwFnufi5w6VH2uQM4MG3Zre4+9a16N7Dq2EuuslQrhtNMluEJTXUVkdp1THeUc/eh6IxqgP82z/f+z4Szssu+FXCrmd1jZtcc6UXM7Jqp2VV9fX3zLGkWSi75rRaEiNSy+dxy1Oa8o9mfA3ngGzNs8gJ3Pw+4AniPmb1optdy98+7+wZ339Dd3T3XkmYvumBfi41rDEJEatp8AmJOl9ows7cCrwTe6O5lX8Pdd0Y/9wE3A+fPscaF95QWhLqYRKR2HXGaq5kNUz4IDGg81jczs8uBPwNeHN2hrtw2GSDm7sPR7y8D/vJY36tiUlMtiDFGJtSCEJHadcSAcPeWub6wmd0AXAx0mVkv8GHCrKUUcJuZAdzt7u8ysxXAF939SqAHuDlanwC+6e4/nGsdCy5qQXTGxzUGISI1bbYnyh0zd7+6zOIvzbDtLuDK6PdHgbMrVde8RQHRlZxgQC0IEalh8xmDqE9RF1NnIqsWhIjUNAXEsUo0QKKR9tg4IxqkFpEapoCYi3QbS2JjakGISE1TQMxFupVWG9csJhGpaQqIuUi30aIzqUWkxikg5iLVSsbHGNIYhIjUMAXEXKTbaCoOMzKRZ4aTwUVEnvEUEHORbiNdGMUdRid1VzkRqU0KiLlIt5HKh6uQ6IJ9IlKrFBBzkW4j7jlS5HTBPhGpWQqIuSi9oqumuopIjVJAzMVUQJhOlhOR2qWAmIvGJQC0MaoxCBGpWQqIuUiHgAgtCI1BiEhtUkDMxaExCN00SERqlwJiLg6NQYwypC4mEalRCoi5iO4J0ZXIagxCRGqWAmIukmlIpKPbjmoMQkRqkwJirtJtdMQ1BiEitauiAWFmG81sn5ltLlnWYWa3mdm26Gf7DPu+Jdpmm5m9pZJ1zoluGiQiNa7SLYgvA5dPW3Y98BN3Pwn4SfT8KcysA/gw8DzgfODDMwVJ1aTbwjRXtSBEpEZVNCDc/Q7gwLTFrwa+Ev3+FeA1ZXZ9OXCbux9w94PAbTw9aKor3UaL6zwIEald1RiD6HH33dHve4CeMtusBHaUPO+Nlj2NmV1jZpvMbFNfX9/CVnok6TYyPqJZTCJSs6o6SO3hbjvzuuOOu3/e3Te4+4bu7u4FqmwW0m00FXXbURGpXdUIiL1mthwg+rmvzDY7gdUlz1dFy44f6TbShWHGc3nyhWK1qxERWXDVCIjvAVOzkt4CfLfMNj8CXmZm7dHg9MuiZcePdBtxz5NmUlNdRaQmVXqa6w3AXcApZtZrZm8HPgq81My2AS+JnmNmG8zsiwDufgD4n8BvosdfRsuOH1MX7ENTXUWkNiUq+eLufvUMqy4rs+0m4B0lzzcCGytU2vyVXI9JASEitUhnUs+VrugqIjVOATFXh+4JMapzIUSkJikg5kotCBGpcQqIuSq5L7XuCSEitUgBMVfpcE+IVtTFJCK1SQExV4kUnmikPTamy22ISE1SQMyDpduimwYpIESk9igg5iPdRrtuGiQiNUoBMR/pNtpMtx0VkdqkgJiPdJvOpBaRmqWAmI9DNw1SQIhI7VFAzEfjknDTII1BiEgNUkDMR7qNxsIIB8cmql2JiMiCU0DMR7qNOAXy2VEGxzRQLSK1RQExHyXXY9pxcKzKxYiILCwFxHyUXI/pyQMKCBGpLQqI+TjUghhVQIhIzVFAzEcUECvSEwoIEak5Coj5iG4atDaTZ4cCQkRqzKIHhJmdYmb3lzyGzOx907a52MwGS7b5i8Wuc1aiFsSqxkm1IESk5iQW+w3d/XfAOQBmFgd2AjeX2fQX7v7KxaztmKXCPSGWpybYuXOcfKFIIq5GmYjUhmp/m10GPOLuT1S5jrlJNECyie5klnzR2T2YrXZFIiILptoB8QbghhnWXWhmD5jZD8zsjJlewMyuMbNNZrapr6+vMlUeSbqN9vg4gMYhRKSmVC0gzKwBeBXwL2VW3wuc6O5nA58G/nWm13H3z7v7Bnff0N3dXZlijyTdRgujABqHEJGaUs0WxBXAve6+d/oKdx9y95Ho91uApJl1LXaBsxJdjykRMwWEiNSUagbE1czQvWRmy8zMot/PJ9TZv4i1zV56CZYdZFV7owJCRGrKos9iAjCzDPBS4J0ly94F4O7/APwB8G4zywPjwBvc3atR61Gl22D/71nd0aQxCBGpKVUJCHcfBTqnLfuHkt8/A3xmseuak5YeGNrFSSuL3LxTASEitaPas5ie+U5/LRQmeHHuTg6O5RjS/alFpEYoIOZr5XnQfRpn9f0boKmuIlI7FBDzZQbnvpH2Aw+wznYqIESkZiggFsJZr8djCf5T/OeaySQiNUMBsRCal2InvZzXJe6kt3+o2tWIiCwIBcRCOfdNdDPAkl2/qHYlIiILQgGxUE56KUPxdi46cDOMlFwTamAH/OZLcOsHw+8iIs8QVTkPoibFkzy0/LVc2LsR/nY9Y6luUpklxA9sizYw2PRPcNlfwHPfAbF4VcsVETkaBcQCOuONH+XffvQ8dm39NV2jv6czO0LzqX/Kc17yeiyRhv/3X+EHfwb3fxNOfD60roSWZWAxKBbCjKj1l0Fje7UPRUQEO16vYDEXGzZs8E2bNlW7DAAe3jXEX/9gC7/Ytp9LT13K37zuLLqbG+C3N8K/fwIOPgG50afvmGqDC98DF7wb0q2LX7iI1BUzu8fdN5Rdp4ConGLR+epdj/PXP9hKKhHjJaf18OJTunnhSd10NCUhOwDD0cVsY3EYOwD//kn43fdDK2Lti6H7VOg+OazbtwX6fgddJ8Fz3gorzqnm4YlIDVBAVNm2vcN85vbt3PH7Pg6O5YgZXHrqUt7w3BO4+JTup9+mdOe98MtPw6774ODjQPQZpdug8yTY+xDkx2HFudB1CozshZF90NAEy8+GZWdBsjEKlK2Qn4DlZ8Hyc6B5aQiZvq2QHYTV58OaF0HnutDFJSJ1RQFxnCgUnQd3DvLDzXu46Z5e9o9M0NOa4hVnruDKM5dx3gntxGLTvqRz49D/CDR1QMvy8CU+PgC//We492uhFdLcEx7ZQdjzW5iIzsWIJaBjHcQboG8LFPOHXzfZFB5j+8PzxnZoaA7bNmSgfQ10rg8/E6kwTuJFGNoFA0/C8O6wbuWGEFTDu2HnPbD7Aeg5A5779sNjKXsfgrs+C7EYbHh7+ZZPsRACLTsAK84LYSciFaeAOA7lCkV+unUf/7Kplzu29TGZL9LTmuIlp/XwktN7eP66TlKJOcx0Khbh4GOh1dC5Ptw3GyCXhX0PwdjB0EXVtjqETf92ePwXsPu3YZ98FiZH4MBj4XVKQ2VKUyc0Lwvrc9POHG9ZAcO7IJmB894cwuR33w/P8bD9queG7rPCRHjPA4/Bjl/DxGB4jXhD2GbFuSHE4g0hXAp5KOagkAt1FSZDveMHQxfc5AgsOxPWvDDsP7QrBNa+LeGYT74cuk8J79H/SGihQZgo0LI81DfaFx4NzbDyOdC45PCxjQ+E925epDsXuqtVJxWngDjODWdz/HTrPn7w4B7u2NbH2GSBTEOcC9d1ctH6Ll54Uhfrupuxxf6yKOTDl32h5Aq1zT2Qaj68ft/D4Uu4ZVn4yz/TCXseDF1km78dvmgveDecf01ohTxwQzgvpH976AZLpELYnHABnHBh6EZ74k547I7wxV6YfHpdsWTYL54M4dHYDo0dYdmu+0IrpFRTJ4xF95tqWw0Tw0/fZiadJ4XXP/DI4dfIdEPPs0OoDO8OQZQfD917K58TuviaOiDVGsaW9m0J/yYHHg1deSvOC0FWLIQ6soOARWFu0Psb2P6T8G/QvgbO+yM46/XhNSH8ETD4ZGiZ7X04HPfJl4exqtkoFkPgiqCAeEbJ5grc9Ug/P2/or5EAABGFSURBVN6yl19s23/o2k5LW1Jc8KxOLlzXyTmrl7Cuu5mGxHH+P/nYgfDl1ZB5+rrZ/nXsHr5Ii/kQCEc7f6RYDC2lnfdA66ow9tK8FAZ7Ydut8MhPwxf+yg3hyzzeEL7kh3eDxSHTFR6j+2HnJui9J7RMOteF7rpYIvpifjCcENm6HFpXhOWHxoxm0NwTxotmY8mJ8KyLQ7DsujfU2dwD2aGoC7HM/7ed68MxQegOLOajVuFEOIaRfeFRmAzbrbkohNnY/nAS52gfJNJh9lyyKWw7tDP8XHYmnPQyWPuiEJQ7fh3+jSEEV1MHtK8N2zUvDcvHB0KwToyE/waSTaHrMNEY/jiYGIa9m8Mjl4XTXw3Lnj27fx9ZMAqIZ7An+8e4c/t+7nq0n7sf7adveAKAZNxY193MqctaOKmnhfVLmzltWSurOxoXv6Uhh432h/Ge7GD4Mi9Mhm6tnjMg1RK+NHfff/gv/8b2w9OZC1H3Wc8Z0PGswwG6Z3NoeY0fDK+Rag2htOzMMMstOwC/+wFs/X74QrZY9IiHL/xEQ/hynhqrAthxN+y6H7wQnseS4Ys9nw11F3OhNde6KtS4+/4QMhiHwinZFIJxYtr1xzJLOdRdN1tTY1w9zw4hNPAk7N8WgjvTFVprTR1hTC47FH6mWsKyxvbwb5JqDsvaVoew7Fgbwung4zDwRDi2WDLUXMzB5Gh4NGTCv3fH2tASLUyGR0OmLs5JUkDUCHfn0f2jbN45yNY9w2zZPcS2vSPsHBg/tE1LOsGzV7RxxopWzljZyhkr2ljblSE5faaUyMRw6OqbCo6p1pn74RbblPwkPHlXGK9qWQarzoelp0M8EdaN9UP/thBmezeHL/yuk8IXdboNJsdCwOTGwpd7PhvCq+eM8Cjk4KGb4YFvhS7LjrXQdXIIwrF+GN4TfiabQgg0ZEJQjB8IyydGyp9XNF9tJ4RWaOf60F2abAzHduh9h8OyZCYE/ZITQ2tzarbgrvtCF2Oy6XDrdOkZ4T4ymS7YtxXu+xo89K+wZDWc80Y44zXhD4wHvhW6aRvb4aJrQwvOLITa9p+Ez+vkK+bdXaiAqHEjE3m27R1m655hNu8cPBQgE/nioW0yDXFa0km6W1KctryF05e3cnJPC10tKToyDbQ3NRCfPoNKpBrmOjhfLMLkcDgJtX97GPNJt4VxnCUnhi/yYv5w+CUzoctrYjhs2/9IaA3FG0LrbuxAmBW4+4HwmsWSsTiLhdZGqjl0j+WiAPTiU2uyWGid5CdCt2X+8B9zZJbC6L7Qoln/kvD+/dtCF1w+C3gYlxvshcEd0HNmCJFHfhqtJ7S4Lv0QnPzyOU9oOC4DwsweB4aBApCfXqCFfpJPAlcCY8Bb3f3eI71mvQZEOflCkUf3j/LQrkGe7B9nOBtuh7p7MMvDu4boH3364G9LKkFrY5KOTAMndDaxrivDmq4MHZkGljQ10NaYpDEZJ52MkU7GSSVi6s6S+lHIhdaPF8IVD6b/5V7Iha6x/kdgZE9oAS0786ljcNnBMK60857Q2lpxDpx5VZgZ5x7GdjbfFMLn7DeEllQhBw/+S5j4MTEMp1wJp/2HMJ51+1+FcFv9PHjzd0MIHqPjOSA2uPv+GdZfCbyXEBDPAz7p7s870msqIGbH3dk3PMEj+0boH53kQPQYHM8xOJ5j/8gET/SP0XtwjOIR/vOIGTQm4zQ2JEglYqSSMRrisRAyTQ20ZxrobknR05qipyXN8iVpVi5ppK0xqWARWQiFHNz/jTBN/ZUfn9NLHCkgjueL9b0a+KqHBLvbzJaY2XJ3313twp7pzIye1jQ9rekjbjeRL9B7cJyBscPhMT5ZJJsrMJ4rMD5ZYGyywHguz0SuyEShyESuyHA2x6P7RzjwxCT9o5NM/xsk0xBnaWuatsbkoUdLOkFLOvwMoRMnETPGc+E93GFVeyMndDSxqr2RTCqhFoxIPBkuu1Mh1QwIB241Mwf+0d0/P239SqD0Bgq90bKnBISZXQNcA3DCCSdUrto6lErEWdfdPK/XyBeK7B+ZZM9Qlj2D4/QeHGfnwDj7RyYZGAuPJ/pHGc7mGcrmyBWOrUWbTsZCoCTjpKNQiZmRiBuNyTiZVIJMQ4LmVILmdPiZKxQZzuYZmciTScVZ3tbIstY07ZkkjckETQ0hoNKJOKlkjOZUgkzqeP5bSqQyqvlf/QvcfaeZLQVuM7Ot7n7Hsb5IFCyfh9DFtNBFyvwk4jGWtaVZ1paG1UuOuK27M5E/3ELJF5zGhjhNDfHQPXtwjCf6x9g1MM54rkA2F207GbVocgWKRacQPcZzBQ6OTrLjwBgjE3lGsnlGJwskYkZLOnzpj07kOTiWO2JdELrSOpsbaI6CYmocNR2FU1NDnNbGJK3pBI0NCfKFIpOFIoWi05xO0JpOkmmIMzpZYGBskuFsnrbGMGmguyVFW2Py0P5g5ItF8lFYxmNGPBYCbyroSmelZXMFDo5F3YRjuXCsE3nyBSeVjJFKxFjS1MCZK9sUdHJMqvZfi7vvjH7uM7ObgfOB0oDYCawueb4qWiY1ysxIJ+Okk3HKRcmpy1o5ddn8LoFeLDpmPKVrKpsrsHswy+B4jrHJPOOTh8NnIl9kKJujf2SC/SOTjEzkiRkYRtGdbL5IdrLAnqEs2/aNMJTNMTZRIBk3kokYMTNGsnkmC4dntzQm4zSnEwyO55jMF8uVeVSlPWuzHUaMGZzcE2awxWJGsehMFooMjuc4MDrJ6ESe1R1NrF/azLO6MiTiMQpFxwndgq3pEGKpRIxE3GiIP7WLLx4zGhKxcOyxGPG4ETeLtp95KmauUGQyXySdjJedSefu9A1PsOPgOKvaG1naklLX4iKpSkCYWQaIuftw9PvLgL+cttn3gD82s28RBqkHNf4g8/W0iyESWgFru8qc7b2AsrkCoxN5MqkE6WQ438DdGcrm6RueYHA8zDIbGg+tmWQ8RiKqtehOvuiMTxYYmcgznM2TLwmcVDIeTVUOX+AtqWTUyjAm8mFcaO9wlvufHODeJw9y96P9mBlm4X2WNCVZ1pom3RDnyf4xvvXrHYznCgt6/Mmoyy+VjBO30CKa6uorfa+GRIxMQ5z2pgaWNCVJxGNs3zfCgZJZd82pBGu7MvS0puhqTkUtuySZVJymhqd2Ee4aGGfbvhG27xshZtDZnKIz00BXcwNdLSm6m1O0ZxpoibofmxoSR5zunc0VyOYKNKcSRwy9WlGtFkQPcHP0V0AC+Ka7/9DM3gXg7v8A3EKYwbSdMM31bVWqVWTeplpGpczs0CB9pZ1OK5ecsnRW2xaLYZZb0Z14zDBgdLLAUBRik/kiuYKTKxSfcsGPQrFILu9MFIoUCkXyxRBsk/limMwwGVpSxSIU3Imb0doYJic0JGJM5IqMR0F6cGySg2OTZHNFXnpaD6cub2F1exO7Bsd5ZN8Ij/WPsXMgywO9gxwYnaRwhOl2ybixpjNDzIx7nzzIgdHJI87Oi8dC6yi0hkIXXdH9UD1TMg2hJTi1XToRpz2TpCOToqMpSToZpyER9k9H4dgQN/qGJ9g5kGX34Dgj2TwT+dCCWt3RyHkntvOcE9rpakmF7lJ38gVnIl9gIlckk0qwpjNDW1P4b2ZsMs8T/WMcHJvk+eu6ZvX5HgudKCciz2juTjZXZGwyz+hEgbFcnrHJAtnJAktb05zY2fSUMZtCMXzZ7x+ZONR6G86GMaqxyQKThQKT0Zf2ZKHIZD58R3ZkkixpaqAxGWdkIs/QeBjvmcyHGXzZyQIHorGgg6OTofU2QxdiZ6aBFUsaaUmHFmUiZmzvG+HRvtmdDb6kKUkyHjt06Z3OTAP3fOilc/r3e6ZOcxUROSozozHqVuqcxaS7eMzoag7dU6cuq2xt7k6u4GTzoWtqIlekqzlFY0P5i04eGJ3k/h0HGc7miUVdcVOtmYZEjOFsnsf3j/JY/yi5fJE1XRlO7GzixI4M7r7gYzMKCBGRCjEzGhJh8L41ffSuxI5MA5ee2rMIlc1O7Y+yiIjInCggRESkLAWEiIiUpYAQEZGyFBAiIlKWAkJERMpSQIiISFkKCBERKaumLrVhZn3AE3PcvQsoe3e7GlaPxwz1edz1eMxQn8d9rMd8ort3l1tRUwExH2a2aabrkdSqejxmqM/jrsdjhvo87oU8ZnUxiYhIWQoIEREpSwFx2PR7YteDejxmqM/jrsdjhvo87gU7Zo1BiIhIWWpBiIhIWQoIEREpq+4DwswuN7Pfmdl2M7u+2vVUipmtNrPbzexhM3vIzK6NlneY2W1mti362V7tWheamcXN7D4z+3/R87Vm9qvoM/9nM2uodo0LzcyWmNlNZrbVzLaY2YW1/lmb2X+N/tvebGY3mFm6Fj9rM9toZvvMbHPJsrKfrQWfio7/t2Z23rG8V10HhJnFgb8HrgBOB642s9OrW1XF5IE/dffTgQuA90THej3wE3c/CfhJ9LzWXAtsKXn+N8Dfuft64CDw9qpUVVmfBH7o7qcCZxOOv2Y/azNbCfwJsMHdnw3EgTdQm5/1l4HLpy2b6bO9AjgpelwDfO5Y3qiuAwI4H9ju7o+6+yTwLeDVVa6pItx9t7vfG/0+TPjCWEk43q9Em30FeE11KqwMM1sFvAL4YvTcgEuBm6JNavGY24AXAV8CcPdJdx+gxj9rwi2UG80sATQBu6nBz9rd7wAOTFs802f7auCrHtwNLDGz5bN9r3oPiJXAjpLnvdGymmZma4BzgV8BPe6+O1q1Bzh+boi7MD4B/BlQjJ53AgPuno+e1+JnvhboA/4p6lr7opllqOHP2t13An8LPEkIhkHgHmr/s54y02c7r++4eg+IumNmzcC3gfe5+1DpOg9znmtm3rOZvRLY5+73VLuWRZYAzgM+5+7nAqNM606qwc+6nfDX8lpgBZDh6d0wdWEhP9t6D4idwOqS56uiZTXJzJKEcPiGu38nWrx3qskZ/dxXrfoq4CLgVWb2OKH78FJC3/ySqBsCavMz7wV63f1X0fObCIFRy5/1S4DH3L3P3XPAdwiff61/1lNm+mzn9R1X7wHxG+CkaKZDA2FQ63tVrqkior73LwFb3P3jJau+B7wl+v0twHcXu7ZKcfcPuPsqd19D+Gx/6u5vBG4H/iDarKaOGcDd9wA7zOyUaNFlwMPU8GdN6Fq6wMyaov/Wp465pj/rEjN9tt8D3hzNZroAGCzpijqquj+T2syuJPRTx4GN7v5XVS6pIszsBcAvgAc53B//PwjjEDcCJxAulX6Vu08fAHvGM7OLgf/u7q80s2cRWhQdwH3Am9x9opr1LTQzO4cwMN8APAq8jfAHYc1+1mb2EeD1hBl79wHvIPS319RnbWY3ABcTLuu9F/gw8K+U+WyjsPwMobttDHibu2+a9XvVe0CIiEh59d7FJCIiM1BAiIhIWQoIEREpSwEhIiJlKSBERKQsBYTIMTCzgpndX/JYsAvemdma0it0ilRb4uibiEiJcXc/p9pFiCwGtSBEFoCZPW5m/8fMHjSzX5vZ+mj5GjP7aXQt/p+Y2QnR8h4zu9nMHogez49eKm5mX4jua3CrmTVW7aCk7ikgRI5N47QupteXrBt09zMJZ65+Ilr2aeAr7n4W8A3gU9HyTwE/d/ezCddJeihafhLw9+5+BjAAvK7CxyMyI51JLXIMzGzE3ZvLLH8cuNTdH40uirjH3TvNbD+w3N1z0fLd7t5lZn3AqtLLPkSXYb8tuukLZvZ+IOnu/6vyRybydGpBiCwcn+H3Y1F6naACGieUKlJAiCyc15f8vCv6/ZeEK8kCvJFwwUQIt4V8Nxy6Z3bbYhUpMlv660Tk2DSa2f0lz3/o7lNTXdvN7LeEVsDV0bL3Eu7sdh3hLm9vi5ZfC3zezN5OaCm8m3AnNJHjhsYgRBZANAaxwd33V7sWkYWiLiYRESlLLQgRESlLLQgRESlLASEiImUpIEREpCwFhIiIlKWAEBGRsv5/p6yICbVLnWkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjaZKIy_WfGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}