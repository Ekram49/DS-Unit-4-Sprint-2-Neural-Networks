{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ekram LS_DS_433_Keras_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekram49/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Ekram_LS_DS_433_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH3Oop8M9Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import statements\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD52wRx8NyMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woFs48h9PvMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "121f3162-22d1-4ee7-fd4a-c173546e7b4c"
      },
      "source": [
        "inputs = x_train.shape[1]\n",
        "epochs = 75\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Create Model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Fit Model\n",
        "results = model.fit(x_train, y_train, \n",
        "          validation_data=(x_test,y_test), \n",
        "          epochs=epochs, \n",
        "          batch_size=batch_size\n",
        "         )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 536.4283 - mae: 21.1431 - val_loss: 481.2335 - val_mae: 19.8471\n",
            "Epoch 2/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 335.1765 - mae: 15.7769 - val_loss: 205.5677 - val_mae: 12.2889\n",
            "Epoch 3/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 107.4552 - mae: 8.0585 - val_loss: 69.4543 - val_mae: 6.4518\n",
            "Epoch 4/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 47.1853 - mae: 4.9117 - val_loss: 37.9270 - val_mae: 4.8110\n",
            "Epoch 5/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 30.6886 - mae: 3.8700 - val_loss: 27.9048 - val_mae: 4.1740\n",
            "Epoch 6/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.8108 - mae: 3.4719 - val_loss: 24.9962 - val_mae: 3.9185\n",
            "Epoch 7/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 21.4561 - mae: 3.2236 - val_loss: 22.5940 - val_mae: 3.7109\n",
            "Epoch 8/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 18.9947 - mae: 3.0434 - val_loss: 21.0440 - val_mae: 3.5313\n",
            "Epoch 9/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 17.1996 - mae: 2.9053 - val_loss: 20.4198 - val_mae: 3.4523\n",
            "Epoch 10/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.9495 - mae: 2.7875 - val_loss: 20.5745 - val_mae: 3.4482\n",
            "Epoch 11/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 14.9147 - mae: 2.7627 - val_loss: 20.4988 - val_mae: 3.3396\n",
            "Epoch 12/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.7769 - mae: 2.6194 - val_loss: 20.5351 - val_mae: 3.3319\n",
            "Epoch 13/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 13.1025 - mae: 2.5714 - val_loss: 20.9702 - val_mae: 3.3288\n",
            "Epoch 14/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.6486 - mae: 2.5605 - val_loss: 20.5928 - val_mae: 3.2610\n",
            "Epoch 15/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 11.9233 - mae: 2.4601 - val_loss: 20.1733 - val_mae: 3.1742\n",
            "Epoch 16/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 11.4125 - mae: 2.4393 - val_loss: 20.6223 - val_mae: 3.1688\n",
            "Epoch 17/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 11.0145 - mae: 2.3877 - val_loss: 20.5879 - val_mae: 3.1228\n",
            "Epoch 18/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 10.6634 - mae: 2.3591 - val_loss: 21.2986 - val_mae: 3.1300\n",
            "Epoch 19/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 10.1444 - mae: 2.3071 - val_loss: 21.0372 - val_mae: 3.1025\n",
            "Epoch 20/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 10.1256 - mae: 2.2723 - val_loss: 20.9141 - val_mae: 3.0902\n",
            "Epoch 21/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 9.8771 - mae: 2.2670 - val_loss: 21.1691 - val_mae: 3.0584\n",
            "Epoch 22/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 9.6147 - mae: 2.2094 - val_loss: 21.6772 - val_mae: 3.1128\n",
            "Epoch 23/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 9.3495 - mae: 2.2152 - val_loss: 21.8979 - val_mae: 3.0592\n",
            "Epoch 24/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 9.2776 - mae: 2.1977 - val_loss: 22.0609 - val_mae: 3.0684\n",
            "Epoch 25/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.9673 - mae: 2.1318 - val_loss: 21.4435 - val_mae: 3.0089\n",
            "Epoch 26/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.9442 - mae: 2.1556 - val_loss: 21.7018 - val_mae: 3.0020\n",
            "Epoch 27/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.9963 - mae: 2.1692 - val_loss: 22.0075 - val_mae: 3.0218\n",
            "Epoch 28/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.7223 - mae: 2.1176 - val_loss: 21.7659 - val_mae: 3.0110\n",
            "Epoch 29/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.6453 - mae: 2.1014 - val_loss: 21.2387 - val_mae: 2.9669\n",
            "Epoch 30/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.7002 - mae: 2.1134 - val_loss: 21.4786 - val_mae: 2.9614\n",
            "Epoch 31/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.3550 - mae: 2.0904 - val_loss: 21.8412 - val_mae: 3.0108\n",
            "Epoch 32/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.3372 - mae: 2.0631 - val_loss: 21.8109 - val_mae: 2.9945\n",
            "Epoch 33/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.3082 - mae: 2.0573 - val_loss: 22.7346 - val_mae: 3.0777\n",
            "Epoch 34/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.3411 - mae: 2.0748 - val_loss: 20.8155 - val_mae: 2.9088\n",
            "Epoch 35/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 8.1970 - mae: 2.0364 - val_loss: 20.3680 - val_mae: 2.8813\n",
            "Epoch 36/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.8983 - mae: 2.0118 - val_loss: 20.4412 - val_mae: 2.8895\n",
            "Epoch 37/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.8942 - mae: 2.0128 - val_loss: 23.1202 - val_mae: 3.0883\n",
            "Epoch 38/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.7843 - mae: 2.0126 - val_loss: 20.8408 - val_mae: 2.8910\n",
            "Epoch 39/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.5820 - mae: 1.9652 - val_loss: 20.8747 - val_mae: 2.9342\n",
            "Epoch 40/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.5155 - mae: 1.9778 - val_loss: 19.2959 - val_mae: 2.8443\n",
            "Epoch 41/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.5685 - mae: 1.9764 - val_loss: 19.7024 - val_mae: 2.8087\n",
            "Epoch 42/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.5010 - mae: 1.9661 - val_loss: 20.1366 - val_mae: 2.8412\n",
            "Epoch 43/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.2929 - mae: 1.9294 - val_loss: 20.1200 - val_mae: 2.8448\n",
            "Epoch 44/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.0740 - mae: 1.9078 - val_loss: 19.9838 - val_mae: 2.9149\n",
            "Epoch 45/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.1246 - mae: 1.9065 - val_loss: 19.4618 - val_mae: 2.8250\n",
            "Epoch 46/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.3263 - mae: 1.9673 - val_loss: 18.8788 - val_mae: 2.7714\n",
            "Epoch 47/75\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 7.0509 - mae: 1.9101 - val_loss: 18.9506 - val_mae: 2.7440\n",
            "Epoch 48/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.8288 - mae: 1.8559 - val_loss: 21.0071 - val_mae: 2.9339\n",
            "Epoch 49/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 7.0002 - mae: 1.9052 - val_loss: 20.7807 - val_mae: 2.9370\n",
            "Epoch 50/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.9501 - mae: 1.8858 - val_loss: 18.5927 - val_mae: 2.7396\n",
            "Epoch 51/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.8807 - mae: 1.9008 - val_loss: 20.2523 - val_mae: 2.9000\n",
            "Epoch 52/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.6601 - mae: 1.8278 - val_loss: 18.8610 - val_mae: 2.7262\n",
            "Epoch 53/75\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 6.6202 - mae: 1.8196 - val_loss: 20.7778 - val_mae: 2.9407\n",
            "Epoch 54/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.8256 - mae: 1.8473 - val_loss: 20.2841 - val_mae: 2.8653\n",
            "Epoch 55/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.6037 - mae: 1.8441 - val_loss: 19.4700 - val_mae: 2.7951\n",
            "Epoch 56/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.6157 - mae: 1.8182 - val_loss: 18.5908 - val_mae: 2.7231\n",
            "Epoch 57/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.2001 - mae: 1.7901 - val_loss: 17.8391 - val_mae: 2.6343\n",
            "Epoch 58/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.3184 - mae: 1.8062 - val_loss: 19.5274 - val_mae: 2.9428\n",
            "Epoch 59/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.3410 - mae: 1.7994 - val_loss: 18.0609 - val_mae: 2.7854\n",
            "Epoch 60/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.5639 - mae: 1.8732 - val_loss: 18.1688 - val_mae: 2.6691\n",
            "Epoch 61/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.0946 - mae: 1.7813 - val_loss: 18.0375 - val_mae: 2.7231\n",
            "Epoch 62/75\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 6.1208 - mae: 1.7734 - val_loss: 19.0041 - val_mae: 2.9397\n",
            "Epoch 63/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.9207 - mae: 1.7489 - val_loss: 18.1585 - val_mae: 2.6720\n",
            "Epoch 64/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.8018 - mae: 1.7455 - val_loss: 16.5222 - val_mae: 2.5731\n",
            "Epoch 65/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 6.0352 - mae: 1.7668 - val_loss: 19.3171 - val_mae: 2.8853\n",
            "Epoch 66/75\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 5.8462 - mae: 1.7202 - val_loss: 17.5663 - val_mae: 2.6675\n",
            "Epoch 67/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.7637 - mae: 1.7522 - val_loss: 16.7206 - val_mae: 2.6022\n",
            "Epoch 68/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.8956 - mae: 1.7451 - val_loss: 17.5157 - val_mae: 2.6827\n",
            "Epoch 69/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.6436 - mae: 1.7163 - val_loss: 16.5293 - val_mae: 2.5908\n",
            "Epoch 70/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.6984 - mae: 1.7357 - val_loss: 17.8321 - val_mae: 2.7842\n",
            "Epoch 71/75\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 6.0033 - mae: 1.7344 - val_loss: 16.0596 - val_mae: 2.6140\n",
            "Epoch 72/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.5141 - mae: 1.6877 - val_loss: 17.4984 - val_mae: 2.6742\n",
            "Epoch 73/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.5782 - mae: 1.6870 - val_loss: 17.1719 - val_mae: 2.7050\n",
            "Epoch 74/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.5763 - mae: 1.7114 - val_loss: 15.7952 - val_mae: 2.5756\n",
            "Epoch 75/75\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.4798 - mae: 1.7048 - val_loss: 16.3432 - val_mae: 2.5803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT2h7Lp3eK_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6b0ecc7a-2fc9-4551-93cc-686707804d0c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "\n",
        "plt.title('Model Loss ')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show();"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZSkdX3v8fe31u7q7umZ6W6GWZAZYVBQZMAJgaBGIcoiUXJVgkskHm4myTEEj4YIuWouubk3mHujSK5LUIkYg4ZACFzFCCJoXBAHBBwYcAYEpmdterbeu6vqe//4/aq6pmfrWaqrZp7P65w6VfU8T1V9q6r7+dTv9yw/c3dEREQAUo0uQEREmodCQUREqhQKIiJSpVAQEZEqhYKIiFQpFEREpEqhILIfZrbYzNzMMtNY9vfN7IczUZdIPSgU5KhiZs+b2biZdU+Z/vO4Yl/cmMoOLFxEGkWhIEejXwHvrtwxs1OBQuPKETlyKBTkaPRPwPtr7l8OfLV2ATPrNLOvmlmfmb1gZh8zs1Sclzaz/2NmL5nZc8Bb9/DYL5vZRjNbb2Z/bWbpQynYzBaY2d1mttXM1prZH9TMO9PMVprZTjPbbGafitNbzOxrZtZvZtvN7GdmNu9Q6hBRKMjR6CFglpmdHFfWlwFfm7LM3wOdwMuB3ySEyAfivD8ALgZOB5YD75zy2K8AReDEuMxbgP96iDV/A+gFFsTX+19mdm6c9xngM+4+CzgBuC1Ovzy+h+OALuCPgJFDrEMSTqEgR6tKa+HNwGpgfWVGTVBc6+4D7v488HfA78VFLgVucPd17r4V+Juax84DLgI+5O5D7r4F+HR8voNiZscB5wAfdfdRd38M+BKTrZ0J4EQz63b3QXd/qGZ6F3Ciu5fc/RF333mwdYiAQkGOXv8EvAf4faZ0HQHdQBZ4oWbaC8DCeHsBsG7KvIrj42M3xi6b7cA/AMccQq0LgK3uPrCXeq4ATgKejl1EF8fp/wR8B/iGmW0ws781s+wh1CGiUJCjk7u/QNjgfBHwb1Nmv0T4lX18zbSXMdma2EjokqmdV7EOGAO63X12vMxy91cdQrkbgLlm1rGnetx9jbu/mxA8nwRuN7M2d59w9+vc/RTgNwhdXu9H5BAoFORodgVwrrsP1U509xKhX/5/mlmHmR0PfJjJ7Q63AX9qZovMbA5wTc1jNwL3An9nZrPMLGVmJ5jZbx5AXfm4kbjFzFoIK/8fA38Tp70m1v41ADN7n5n1uHsZ2B6fo2xmbzKzU2N32E5C0JUPoA6R3SgU5Kjl7s+6+8q9zL4SGAKeA34I3ArcHOd9kdAt8zjwKLu3NN4P5ICngG3A7cD8AyhtkLBBuHI5l7AL7WJCq+FO4C/d/btx+QuAJ81skLDR+TJ3HwGOja+9k7Dd5PuELiWRg2YaZEdERCrUUhARkSqFgoiIVCkURESkSqEgIiJVR/TZGru7u33x4sWNLkNE5IjyyCOPvOTuPXuad0SHwuLFi1m5cm97HIqIyJ6Y2Qt7m6fuIxERqVIoiIhIlUJBRESqjuhtCiIiB2NiYoLe3l5GR0cbXUpdtbS0sGjRIrLZ6Z88V6EgIonT29tLR0cHixcvxswaXU5duDv9/f309vayZMmSaT9O3Ucikjijo6N0dXUdtYEAYGZ0dXUdcGtIoSAiiXQ0B0LFwbzHRIbCz57fyv/+ztOUyzpDrIhIrUSGwuPrtvPZB55laLzY6FJEJIG2b9/O5z73uQN+3EUXXcT27dv3v+AhSGQotOfD9vXBMYWCiMy8vYVCsbjvddI999zD7Nmz61UWkNC9j9pbYiiMFqGzwcWISOJcc801PPvssyxbtoxsNktLSwtz5szh6aef5pe//CWXXHIJ69atY3R0lKuuuooVK1YAk6f2GRwc5MILL+R1r3sdP/7xj1m4cCF33XUXra2th1xbMkMhthQG1FIQSbzr/t+TPLVh52F9zlMWzOIvf/tVe51//fXXs2rVKh577DEefPBB3vrWt7Jq1arqrqM333wzc+fOZWRkhF/7tV/jHe94B11dXbs8x5o1a/j617/OF7/4RS699FLuuOMO3ve+9x1y7YkMhY7aloKISIOdeeaZuxxLcOONN3LnnXcCsG7dOtasWbNbKCxZsoRly5YB8NrXvpbnn3/+sNSSyFBoz4ej+wYUCiKJt69f9DOlra2tevvBBx/ku9/9Lj/5yU8oFAq88Y1v3OOxBvl8vno7nU4zMjJyWGpJ5obmSkthbKLBlYhIEnV0dDAwMLDHeTt27GDOnDkUCgWefvppHnrooRmtLaEthbhNQS0FEWmArq4uzjnnHF796lfT2trKvHnzqvMuuOACvvCFL3DyySfzile8grPOOmtGa0t0KGiXVBFplFtvvXWP0/P5PN/+9rf3OK+y3aC7u5tVq1ZVp//Zn/3ZYasrkd1H6ZRRyKW1oVlEZIpEhgKEPZDUUhAR2VVdQ8HMnjezX5jZY2a2Mk6ba2b3mdmaeD0nTjczu9HM1prZE2Z2Rj1ra89ndJyCiMgUM9FSeJO7L3P35fH+NcD97r4UuD/eB7gQWBovK4DP17Oo9pasuo9ERKZoRPfR24Fb4u1bgEtqpn/Vg4eA2WY2v15FdOTVfSQiMlW9Q8GBe83sETNbEafNc/eN8fYmoLIv1kJgXc1je+O0XZjZCjNbaWYr+/r6Drqw9nxGLQURkSnqHQqvc/czCF1DHzSzN9TOdHcnBMe0uftN7r7c3Zf39PQcdGHt2tAsIg1ysKfOBrjhhhsYHh4+zBVNqmsouPv6eL0FuBM4E9hc6RaK11vi4uuB42oevihOq4v2fIaBUR3RLCIzr5lDoW4Hr5lZG5By94F4+y3AXwF3A5cD18fru+JD7gb+xMy+Afw6sKOmm+mwq+yS6u6JGJZPRJpH7amz3/zmN3PMMcdw2223MTY2xu/8zu9w3XXXMTQ0xKWXXkpvby+lUomPf/zjbN68mQ0bNvCmN72J7u5uHnjggcNeWz2PaJ4H3BlXuBngVnf/DzP7GXCbmV0BvABcGpe/B7gIWAsMAx+oY2205zOUHUYmShRyiTywW0QAvn0NbPrF4X3OY0+FC6/f6+zaU2ffe++93H777Tz88MO4O29729v4wQ9+QF9fHwsWLOBb3/oWEM6J1NnZyac+9SkeeOABuru7D2/NUd3Whu7+HHDaHqb3A+ftYboDH6xXPVPVDrSjUBCRRrn33nu59957Of300wEYHBxkzZo1vP71r+cjH/kIH/3oR7n44ot5/etfPyP1JHNt+JPPctl9/52/4iYGxooc0+h6RKRx9vGLfia4O9deey1/+Id/uNu8Rx99lHvuuYePfexjnHfeeXziE5+oez3JPM2FpUmXx2lhXLulisiMqz119vnnn8/NN9/M4OAgAOvXr2fLli1s2LCBQqHA+973Pq6++moeffTR3R5bD8lsKWTDOKatjOn02SIy42pPnX3hhRfynve8h7PPPhuA9vZ2vva1r7F27VquvvpqUqkU2WyWz38+nORhxYoVXHDBBSxYsOCI29DcvLIFAFptXAPtiEhDTD119lVXXbXL/RNOOIHzzz9/t8ddeeWVXHnllXWrK5ndR7kQCgW1FEREdpHMUIjdRy2M6ahmEZEaCQ2Fmu4jtRREEinsBX90O5j3mOhQmJWeUEtBJIFaWlro7+8/qoPB3env76elpeWAHpfoDc1zshMaaEckgRYtWkRvby+HcqblI0FLSwuLFi06oMckNBTCNoXZmSLr1H0kkjjZbJYlS5Y0uoymlNDuoxAKszLqPhIRqZXMUMi1AdCZntCGZhGRGskMhXQOLEV7WtsURERqJTMUzCBboD2lI5pFRGolMxQAsq0UUjpOQUSkVoJDoUAhHtF8NO+rLCJyIBIdCq2MM1FyxorlRlcjItIUEhwKrbQwBqDdUkVEogSHQoGcx1DQdgURESDJoZArkCuPAOj02SIiUXJDIdtKthxaCgPaLVVEBEh0KBTIlEYBdR+JiFQkOBRaSZdC95E2NIuIBAkOhQKp4jCgUBARqUh0KDAxArg2NIuIRAkOhVYMpy1dVEtBRCRKcCiE0dd6ciVtaBYRiZIbCrkQCl35kloKIiJR3UPBzNJm9nMz+2a8v8TMfmpma83sX8wsF6fn4/21cf7iuhZWGac5V9I2BRGRaCZaClcBq2vufxL4tLufCGwDrojTrwC2xemfjsvVTxySc262qDEVRESiuoaCmS0C3gp8Kd434Fzg9rjILcAl8fbb433i/PPi8vURQ2FOVuM0i4hU1LulcAPw50Dl3NRdwHZ3r6yFe4GF8fZCYB1AnL8jLr8LM1thZivNbGVfX9/BV5aN4zRnitrQLCIS1S0UzOxiYIu7P3I4n9fdb3L35e6+vKen5+CfKLYUOjJqKYiIVGTq+NznAG8zs4uAFmAW8BlgtpllYmtgEbA+Lr8eOA7oNbMM0An01626uKF5VnpCG5pFRKK6tRTc/Vp3X+Tui4HLgO+5+3uBB4B3xsUuB+6Kt++O94nzv+f1HCez0lJIjTNWLDOu0ddERBpynMJHgQ+b2VrCNoMvx+lfBrri9A8D19S1inicQltqHND5j0REoL7dR1Xu/iDwYLz9HHDmHpYZBd41E/UA1e6jgoXdUQdHi8xty83Yy4uINKPkHtGczoGlaEUD7YiIVCQ3FMwgW6iGgnZLFRFJcigAZAvkK6GgbQoiIkkPhVbyHofkVCiIiCQ9FApky3GbgrqPRESSHgqtZDVOs4hIVbJDIddGqjRCyrShWUQEkh4K2VZsYoT2fEYtBRERFAowPkxHS1bbFERESHwoFKDaUtDBayIiCoWJYdpb1H0kIgKJD4XWyZaCuo9ERJIeCrGlkE8zoJaCiEjSQ6EVcObkymopiIiQ9FDIhXGa52SL2qYgIkLSQyGOvtaZnWB4vESxpNHXRCTZEh4KYaCdznTYHXVorNTIakREGi7hoRBbCpnQdaSBdkQk6RIeCqGl0J6KQ3Jqu4KIJJxCASikwumz1X0kIkmX8FAI3UdtNg7A8LhaCiKSbAkPhdBSqIzTPKTuIxFJuGSHQq4SCqGloO4jEUm6ZIdC7D6qjNOs7iMRSbqEh0JoKeRiKAyqpSAiCZfsUEjnwFJky2OYqaUgIpLsUDCDbBs2MUJbTmMqiIgkOxQgjqkwRFs+zbC6j0Qk4eoWCmbWYmYPm9njZvakmV0Xpy8xs5+a2Voz+xczy8Xp+Xh/bZy/uF617SIOtNOWyzCk7iMRSbh6thTGgHPd/TRgGXCBmZ0FfBL4tLufCGwDrojLXwFsi9M/HZervzjQTls+o+MURCTx6hYKHgzGu9l4ceBc4PY4/Rbgknj77fE+cf55Zmb1qq8qV4CJEQq5NEPj6j4SkWSr6zYFM0ub2WPAFuA+4Flgu7tXfpL3Agvj7YXAOoA4fwfQtYfnXGFmK81sZV9f36EXmS3AuFoKIiJQ51Bw95K7LwMWAWcCrzwMz3mTuy939+U9PT2HXGPYphBCYVgtBRFJuBnZ+8jdtwMPAGcDs80sE2ctAtbH2+uB4wDi/E6gv+7FVTc0p7VLqogk3rRCwczazCwVb59kZm8zs+x+HtNjZrPj7VbgzcBqQji8My52OXBXvH13vE+c/z139wN5Mwcl2xZCIZ9hWKEgIgk33ZbCD4AWM1sI3Av8HvCV/TxmPvCAmT0B/Ay4z92/CXwU+LCZrSVsM/hyXP7LQFec/mHgmgN5IwetcpxCLs3wRIlyuf45JCLSrDL7XwQAc/dhM7sC+Jy7/23cgLxX7v4EcPoepj9H2L4wdfoo8K5p1nP4xO6jQj6DO4xMlGjLT/djERE5uky3pWBmdjbwXuBbcVq6PiXNsMpxCrnwdnQAm4gk2XRD4UPAtcCd7v6kmb2csG3gyBfHVOjIhDDQmAoikmTT6idx9+8D3weIG5xfcvc/rWdhMyaePntWujLQjloKIpJc09376FYzm2VmbcAq4Ckzu7q+pc2QONBORyqEgY5VEJEkm2730SnuvpNwSopvA0sIeyAd+WJLoS2lcZpFRKYbCtl4XMIlwN3uPkE4j9GRrxoKsftIG5pFJMGmGwr/ADwPtAE/MLPjgZ31KmpGxe6jVtRSEBGZ7obmG4Ebaya9YGZvqk9JMyy2FApW2dCsbQoiklzT3dDcaWafqpyd1Mz+jtBqOPLFlkLeQyhonGYRSbLpdh/dDAwAl8bLTuAf61XUjMqFbMuWRsilUwyqpSAiCTbd8zmc4O7vqLl/3f5Oc3HEiC0FJoYp5OeopSAiiTbdlsKImb2ucsfMzgFG6lPSDKuGQhinWafPFpEkm25L4Y+Ar5pZZ7y/jcnTXB/Z4obmMNBOmmF1H4lIgk1376PHgdPMbFa8v9PMPgQ8Uc/iZkQ6B5YO3Ue5jI5TEJFEO6CR19x9ZzyyGcKYB0c+s3im1BHaNU6ziCTcoQzHaYetikaL4zQXcmmd+0hEEu1QQuHoOM0FVAfaac9rQ7OIJNs+tymY2QB7Xvkb0FqXihoh1wbjQxRa1FIQkWTbZyi4e8dMFdJQsaXQNkstBRFJtkPpPjp6xA3NbfkM48UyE6VyoysSEWkIhQLssqEZNNCOiCSXQgFiS2GY9nzoTdNuqSKSVAoFqHYfFWIo6PxHIpJUCgWodh+150P3kc6UKiJJpVCAEArj4TQXAMPqPhKRhFIoQDhOoThCWzZ8HNotVUSSSqEA1dNnt6dDGGjvIxFJKoUCVE+f3ZaO4zRrQ7OIJFTdQsHMjjOzB8zsKTN70syuitPnmtl9ZrYmXs+J083MbjSztWb2hJmdUa/adhNbCm0WQ0HdRyKSUPVsKRSBj7j7KcBZwAfN7BTgGuB+d18K3B/vA1wILI2XFcDn61jbruI4za3lMJjckPY+EpGEqlsouPtGd3803h4AVgMLgbcDt8TFbgEuibffDnzVg4eA2WY2v1717aLQBUBqdCuFXFotBRFJrBnZpmBmi4HTgZ8C89x9Y5y1CZgXby8E1tU8rDdOm/pcK8xspZmt7OvrOzwFxlBg6KU4+ppaCiKSTHUPBTNrB+4APlQzahsA7u4c4LgM7n6Tuy939+U9PT2Hp8hCd7gefimM06wNzSKSUHUNBTPLEgLhn9393+LkzZVuoXi9JU5fDxxX8/BFcVr9VVoKw1tpy2lIThFJrnrufWTAl4HV7v6pmll3A5fH25cDd9VMf3/cC+ksYEdNN1N9ZXKQ74Sh0FLQhmYRSap9DrJziM4Bfg/4hZk9Fqf9BXA9cJuZXQG8AFwa590DXASsBYaBD9Sxtt21dcXuowxbh8Zn9KVFRJpF3ULB3X9IGLZzT87bw/IOfLBe9exXoSu0FHIZ1m0dblgZIiKNpCOaKwrdMNwfd0lV95GIJJNCoaKtC4b7actndJoLEUkshUJFoTt2H6UYHi8RerNERJJFoVBR6ILyBHMyo5TKzlix3OiKRERmnEKhoi0cwDaXAUAnxRORZFIoVMSjmmdXQ0Ebm0UkeRQKFW3hqObO0nZAYyqISDIpFCpiS6G9vANA5z8SkURSKFTE8x+1FUNLYVDdRyKSQAqFilwbZFponQihMKwNzSKSQAqFCjModNMysQ2AQYWCiCSQQqFWWxfZ0a0ADGugHRFJIIVCrUI3mRgKaimISBIpFGoVurCRftIp095HIpJICoVabd2YzpQqIgmmUKhV6ILxQebmyjrNhYgkkkKhVjz/0fzsoDY0i0giKRRqFSqhMKQNzSKSSAqFWvGo5p7UkDY0i0giKRRqxe6jnvSANjSLSCIpFGrFlkKX7dRZUkUkkRQKtVpmg6WZw061FEQkkRQKtVIpKHTR6Tu1S6qIJJJCYapCFx2lHYxMlCiVvdHViIjMKIXCVG3ddJQ00I6IJJNCYapCF63FcPpsHcAmIkmjUJiqrZuWONCOtiuISNIoFKYqdJEb30GKsvZAEpHEUShMVejGcOYwoFNdiEji1C0UzOxmM9tiZqtqps01s/vMbE28nhOnm5ndaGZrzewJMzujXnXtV1s4gG2uDbBu63DDyhARaYR6thS+AlwwZdo1wP3uvhS4P94HuBBYGi8rgM/Xsa59q5wULzPIUxt3NqwMEZFGqFsouPsPgK1TJr8duCXevgW4pGb6Vz14CJhtZvPrVds+xfMfvWpOkdUKBRFJmJnepjDP3TfG25uAefH2QmBdzXK9cdpuzGyFma00s5V9fX2Hv8J4/qNXdIyxeuNO3HUAm4gkR8M2NHtY2x7wGtfdb3L35e6+vKen5/AXFkNhccswO0eLbNgxevhfQ0SkSc10KGyudAvF6y1x+nrguJrlFsVpMy+dhZZO5meHAFi9QV1IIpIcMx0KdwOXx9uXA3fVTH9/3AvpLGBHTTfTzCt0M9cGAbRdQUQSJVOvJzazrwNvBLrNrBf4S+B64DYzuwJ4Abg0Ln4PcBGwFhgGPlCvuqalrZvsaD8vm1vg6U0DDS1FRGQm1S0U3P3de5l13h6WdeCD9arlgBW6YPuLnDy/Qy0FEUkUHdG8J4UuGHqJk+fP4lf9Gq9ZRJJDobAnbd0w3M/Jx3bgDs+oC0lEEkKhsCeFbihP8KouA2D1RoWCiCSDQmFP4lHNC3NDdOQz2q4gIomhUNiTeACbDffzSm1sFpEEUSjsSffScP3iQ7zy2Fk8vWmAssZrFpEEUCjsyZzFsPC1sOp2Tp4/i8GxIr3bRhpdlYhI3SkU9ubV74SNj7OsdTOATqMtIomgUNibV/8XwFi65TuY6XQXIpIMCoW96TgWlryB7FN3sGRuQaEgIomgUNiXU98FW5/j/LmbWL1JoSAiRz+Fwr6c/NuQznF++Qes2zrCwOhEoysSEakrhcK+tM6GpW/h5P7vkqKsM6aKyFFPobA/p76T/OgWzk6t5l9Xrtv/8iIiRzCFwv6cdAHk2rl64SpuW9nLA89s2f9jRESOUAqF/cm2wisv5rSBBzmlJ8+1d/yCHSPatiAiRyeFwnSc+i5sdAdfPOUx+gbH+OtvPtXoikRE6kKhMB0vfyMsfQsLf/o/+McTvs+/PrKO7z29udFViYgcdgqF6Uhn4LJb4TWX8YZ1X+CGWbfyF3c8zo5hdSOJyNGlbmM0H3XSWbjk89DewyU//nuypX4uuWGCP3rzqbzjjEVk0spXETnymfuRe0ro5cuX+8qVK2f+hX90I9z3cSbIsLJ0EqtbT+eUcy7m18/5LSyTm/l6REQOgJk94u7L9zhPoXCQXnwIf/pbDDz1Xdq3ryaFM0aOTW0nk3nZco455fVkF7wGZr8stDIkqPy9mTW+jtEdMNwPQy9ByyzoOvHAv6vSBGx8HPqfhWNODhd939LkFAp1VhrsZ+X3/50dz/yI7h1P8Cp+Rd6KAJQtzXj7IrI9J5DuXAgtnZDvgPwsyLZAuRQvRfByWFlaKlwwIH4/7mF+cQQmai7pLGTykGkNz5dpDbvRZgvhvpdhfBgm4qVcjM9LeK3SRFg5jmyH0e3xOXPheSvXloZUKlxbCsoT4XGlcSiOhecdHwqvMz4Y5pXj/Mp7q1y8DKls+AxaZoXrVHby+SqX4li8Hg3PUaknlQnvN9cGufZwybaCl3Z9juJYeOzEaLiufI5YeN+jO0ONtVJZ6D4prNhnHwfZtvDcuUJ4bS/Hi8PgFnjxx7Du4fD+KzItcOxr4NhXQzofJ3r43GYthLkvh64Twpgdqczk91j9XodDzRPD4X3XstTk95BKh5pqP4dcW/hs9hW4oztg85OwaRX0rZ78PtLxMvflMH8ZHHMKVFq95RLsWAf9a8PnN2cxdC4KrwUhVLc8BZufgqG+8Hll20I9+XZonQOtc6EwN1znCtP7x4LwWaRz4X3LYaNQmEEj4yV+9MwGVv/8Rwz1rqJteB2LbRPH2xYWpLfTwTB5Hz20F7H05AqgXIwrvkMYBCjbFk7p0dIZVoKlykp/LFx7OawYvBRu7xIauRBAubgSyBZCXalMWCaVDRvqU/Fi6fC8YwPhMrozPO/UIErnw/Okc2EFWJoI77USFJUAGh8KK9BUZjI00tmwcs62xsBsCStUd8DDdcssKHRDW08YfnVk6+SKbctTMLBp99DY9UuAea+G438jXLqXwpbVsP5R2PBoeI5yDHksvMfxwYP/jqYrlQ0r4nxH+F4r79fLIXR29k4u2zI7fD6lcSgVYwDH95zOhXAsjsPW58J3NlXH/PB3MVR7QGfND5m9yRbCZ165tM4OwdEyO9S+oxdeWhNCaOf68Lcw5/gQRnMWh7+zcmkypLFdw7I4FkJ7qC9ciqOToVToCt951wmhZdh1YviBtn4l/Oo/4fkfhpZfx7HQ84rwvXafBO3zauqdE15jZNvkJZ2F9mOg7ZjwOuUi7NwQ3suO3lBn90nQc1L4P4PwvQz3w7YXwmdY+btN50Nwdi6aXPYwUyg0UP/gGD9/cTuPvriNpzbuZM3mQTZtH6SNEVqYoESKfD5Pz6xWjpnVSk97np72HN3tWbrbMvR0tHBMRws9HS205jOhJZDO7v5r0D3+Op7SkkilY8sh/upNZ3ddOVZ+IcruShPxl/tIWHFWWm+WCiumllkH9nzDW8MKtv9Z2PZ8mFZt3bXE1l0hfl+tYQVfy0uT4VwuhZrGhybDcWwg3B4bDLcnhibrtVRY0fecBPNOhWNPDSu+2r+jchm2/SqsFDc+BhufCHV0nQBdS8MK1CysxLa/CNtfCPePOSV2nb0qrBirdcWaRraG9z6yNawEh+P94X4Yfim0Uke2hZaqlyHfCd0nhtec+3IYHwif17bnw2sXR+N7ii1XfNfPJZMPK/62nlBPJh+ev/Lag1umBH4lyAzmnxZGXRzcHIJp67OxdX0Aan+A7En7sSFYdqzb/w+FfGfogp61YNfve2wQzvs4vObSA6utUqJCobkMjxd5dssQv+ofYuP2ETbuGGXD9hE27RzlpYEx+gbHmCjt/r10tGTobM0yqyXLrNYMHS1Z2nJpWnMZWrNpCrn05DKtWTpbs7TnM7Tl0xRyGQq5NK25NLl0Cmt0n77IVOXYPZot1HebU213WP+zoTWx4IzQ4mudveuypYkQgEN9MVRisGRaYnfYnNhyGJ1snQzGX/2dx4DqIBkAAApOSURBVIVf+52LwnP1PQMvPQN9vwwBOPtlk62f9mNCXcXR8ONubCC0kra/GC47N8Ru09hNmO+AZe+BJW84qI9AoXCEcXd2jhTZMjDK5p1jbN45yqado/QNjLFjZIKB0Ql2jhTZOTrB8HiJkYkSI+MlhseLlKfxdZpBSyZNSzZFSzZNSzZNPpMinwn3C7k0hXwmBE42vUuAmEEunSKTNrLpFNl0ilw6RTZtZDOT93PxdjZtpFOGYaQMzIxM2qrL5DIpMnF+5fkByu6h14PwOy6bqX1eI2WGGeGasJx7eByEGlMpBZ/InuwrFHScQhMyMzoLWToLWZbO65j249yd4fESO0Ymqpfh8SJDYyEwBsdKjE5MXkYmSoxOlBkvlhkrlhgrlhkZL/HS4DhDW4cZHgvLVJ47XMNEuUyx5BSnk0ANlEuHoMtldg+Iyj0zqoHk+C47R6XNSKeNtBmZSgBmUuRjKE79MZuyEFbpVLjOpEIAhusUqUqIxXAMrxXDL75u2J4aAjSdMjKpyWDNpFNkUyF8M6kwreyT303ZnYmSUyo7xVKZshMCOFMJ7hjmqXCdSadwd4qVx8TvM3wmk59NJXxTqXCdTYfXz8bgrV3WCc9TLE3WkE4Z2fRk/VPls+HHR+VHCkCp7JTdq++v8pdWCf7xYjm+TplUysIPmWym2hLe7btMTdadTtkeW8ruofZS2avfXz1+WJTKjrs37bFNTRUKZnYB8BkgDXzJ3a9vcElHFDOjLZ+hLZ9hwezWur9euezVgJgoVcIl/LPW3veaf+6Sh3+68eLk/FJcGU3+43vNyjMGUXy+8fha1ZZEfG6DXf6BJ0rhuccmQuDtml+TARdaI75LS8Us9GSU3CnHlWWxXGa86IyXyowXS4wXy0x9xnJcvuzElUt5lxVkdZnqiryywp1coYaV3uRnVflsa1fa05UyptVyTKJK6Fb+zvb2I8cMsqnUZDDG63LN33Kp7NXQqVwqf7eV0C9W/uZLk3/v2bRVu3VbsunJ/5OaQNu1Ztvlh8WHfuskfvu0BYf9s2maUDCzNPBZ4M1AL/AzM7vb3XX2uSaVShn5VJp80/wVHd0qv2QnSmUmSiGAUvFnfWWlVf0FH1sjpery5eqv64lSpaVXjo9JVVtEMLlS8vialfCsrASLNT8Earv53EMdmdjCycRuvmJ58vUmSk7tb++yw3gptFArLdhKSypd0zqpVXnubDq8Tsk9dp+WGBkvMl7zGhaDsRRfu7YVVXKv1l9pzeXSRjqVohwDuVJzNbDLIQxqWxLpGBKV72WsWKbS8VlpdWVSVu0uzaXTmMHIRInhsSLD46GVXlm28p3u+uWzy4+KctmZXajPDiLN9O98JrDW3Z8DMLNvAG8HFAoihBVlNm7Lma50ykin0tVuGZH9aaZOrYVA7dBmvXHaLsxshZmtNLOVfX19M1aciEgSNFMoTIu73+Tuy919eU9PT6PLERE5qjRTKKwHjqu5vyhOExGRGdJMofAzYKmZLTGzHHAZcHeDaxIRSZSm2dDs7kUz+xPgO4RdUm929ycbXJaISKI0TSgAuPs9wD2NrkNEJKmaqftIREQaTKEgIiJVR/QJ8cysD3jhIB/eDbx0GMuphyOhRjgy6lSNh4dqPDwaXePx7r7HffqP6FA4FGa2cm9nCWwWR0KNcGTUqRoPD9V4eDRzjeo+EhGRKoWCiIhUJTkUbmp0AdNwJNQIR0adqvHwUI2HR9PWmNhtCiIisrsktxRERGQKhYKIiFQlMhTM7AIze8bM1prZNY2uB8DMbjazLWa2qmbaXDO7z8zWxOs5Da7xODN7wMyeMrMnzeyqZqvTzFrM7GEzezzWeF2cvsTMfhq/83+JJ11sKDNLm9nPzeybzVijmT1vZr8ws8fMbGWc1jTfdU2ds83sdjN72sxWm9nZzVSnmb0ifoaVy04z+1Az1VgrcaFQM+znhcApwLvN7JTGVgXAV4ALpky7Brjf3ZcC98f7jVQEPuLupwBnAR+Mn10z1TkGnOvupwHLgAvM7Czgk8Cn3f1EYBtwRQNrrLgKWF1zvxlrfJO7L6vZp76ZvuuKzwD/4e6vBE4jfKZNU6e7PxM/w2XAa4Fh4M5mqnEXYQzW5FyAs4Hv1Ny/Fri20XXFWhYDq2ruPwPMj7fnA880usYp9d5FGFO7KesECsCjwK8Tjh7N7OlvoEG1LSKsCM4FvkkYlbfZanwe6J4yram+a6AT+BVxp5lmrbOmrrcAP2rmGhPXUmCaw342iXnuvjHe3gTMa2QxtcxsMXA68FOarM7YLfMYsAW4D3gW2O7uxbhIM3znNwB/DpTj/S6ar0YH7jWzR8xsRZzWVN81sAToA/4xdsV9yczaaL46Ky4Dvh5vN2WNSQyFI5KHnxNNsf+wmbUDdwAfcvedtfOaoU53L3loqi8CzgRe2ch6pjKzi4Et7v5Io2vZj9e5+xmErtYPmtkbamc2w3dNOP3/GcDn3f10YIgp3TBNUidxG9HbgH+dOq9ZaoRkhsKRNOznZjObDxCvtzS4HswsSwiEf3b3f4uTm65OAHffDjxA6IqZbWaV8UMa/Z2fA7zNzJ4HvkHoQvoMzVUj7r4+Xm8h9IGfSfN9171Ar7v/NN6/nRASzVYnhHB91N03x/vNWGMiQ+FIGvbzbuDyePtyQh9+w5iZAV8GVrv7p2pmNU2dZtZjZrPj7VbCNo/VhHB4Z1ysoTW6+7XuvsjdFxP+/r7n7u+liWo0szYz66jcJvSFr6KJvmsAd98ErDOzV8RJ5wFP0WR1Ru9msusImrPG5G1oDq00LgJ+Sehr/m+NrifW9HVgIzBB+PVzBaGf+X5gDfBdYG6Da3wdoYn7BPBYvFzUTHUCrwF+HmtcBXwiTn858DCwltB8zzf6O491vRH4ZrPVGGt5PF6erPyfNNN3XVPrMmBl/M7/HZjTbHUCbUA/0FkzralqrFx0mgsREalKYveRiIjshUJBRESqFAoiIlKlUBARkSqFgoiIVCkURPbBzEpTznB52E5aZmaLa8+KK9IMMvtfRCTRRjycMkMkEdRSEDkIcayBv43jDTxsZifG6YvN7Htm9oSZ3W9mL4vT55nZnXGch8fN7DfiU6XN7Itx7Id741HYIg2jUBDZt9Yp3Ue/WzNvh7ufCvxfwllPAf4euMXdXwP8M3BjnH4j8H0P4zycQThKGGAp8Fl3fxWwHXhHnd+PyD7piGaRfTCzQXdv38P05wmD+TwXTxK4yd27zOwlwjnyJ+L0je7ebWZ9wCJ3H6t5jsXAfR4GWcHMPgpk3f2v6//ORPZMLQWRg+d7uX0gxmpul9B2PmkwhYLIwfvdmuufxNs/Jpz5FOC9wH/G2/cDfwzVQYA6Z6pIkQOhXyUi+9YaR3Gr+A93r+yWOsfMniD82n93nHYlYRSwqwkjgn0gTr8KuMnMriC0CP6YcFZckaaibQoiByFuU1ju7i81uhaRw0ndRyIiUqWWgoiIVKmlICIiVQoFERGpUiiIiEiVQkFERKoUCiIiUvX/ARQKL6ekBMAHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuTWtYP0fFY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e51bc40-d026-4199-f682-43f829007250"
      },
      "source": [
        "# Linear regression model.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj0UEnq6f-yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8UA6a9gCbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a236f38-a473-43e7-ed3f-277f12ac6c1f"
      },
      "source": [
        "mean_squared_error(y_test, predict)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.195599256423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjaZKIy_WfGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}